{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1294502f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ['MMWHS_CACHE_PATH'] = str(Path('.', '.cache'))\n",
    "from slice_inflate.datasets.mmwhs_dataset import MMWHSDataset, load_data, extract_2d_data\n",
    "from slice_inflate.utils.common_utils import DotDict, get_script_dir\n",
    "\n",
    "THIS_SCRIPT_DIR = get_script_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3fce271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MMWHS training images and labels... (['m', 'r'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 images, 0 labels: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postprocessing 3D volumes\n",
      "Removed 0 3D images in postprocessing\n",
      "Equal image and label numbers: True (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m config_dict \u001b[39m=\u001b[39m DotDict({\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mnum_folds\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m5\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39monly_first_fold\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m,                \u001b[39m# If true do not contiue with training after the first fold\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m })\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m config \u001b[39m=\u001b[39m config_dict\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m training_dataset \u001b[39m=\u001b[39m MMWHSDataset(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m     config\u001b[39m.\u001b[39;49mdata_base_path,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     state\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m     load_func\u001b[39m=\u001b[39;49mload_data,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m     use_2d_normal_to\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49muse_2d_normal_to, \u001b[39m# Use 2D slices cut normal to D,H,>W< dimensions\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     do_resample\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m# Prior to cropping, resample image?\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m     crop_3d_region\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, \u001b[39m# Crop or pad the images to these dimensions\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m     pre_interpolation_factor\u001b[39m=\u001b[39;49m\u001b[39m1.\u001b[39;49m, \u001b[39m# When getting the data, resize the data by this factor\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m     ensure_labeled_pairs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m# Only use fully labelled images (segmentation label available)\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m     modality\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmr\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m     device\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mdevice,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m     debug\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mdebug\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brechenknecht01/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/main_slice_inflate.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m )\n",
      "File \u001b[0;32m/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/slice_inflate/datasets/mmwhs_dataset.py:32\u001b[0m, in \u001b[0;36mMMWHSDataset.__init__\u001b[0;34m(self, state, label_tags, *args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, state\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m     label_tags\u001b[39m=\u001b[39m(\n\u001b[1;32m     21\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbackground\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpulmonary_artery\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     29\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m state\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, state\u001b[39m=\u001b[39;49mstate, label_tags\u001b[39m=\u001b[39;49mlabel_tags, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/slice_inflate/datasets/hybrid_id_dataset.py:98\u001b[0m, in \u001b[0;36mHybridIdDataset.__init__\u001b[0;34m(self, base_dir, load_func, ensure_labeled_pairs, do_resample, resample_size, do_normalize, max_load_3d_num, crop_3d_region, modified_3d_label_override, crop_2d_slices_gt_num_threshold, prevent_disturbance, label_tags, use_2d_normal_to, pre_interpolation_factor, device, debug, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39m#check for consistency\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEqual image and label numbers: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_data_3d)\u001b[39m==\u001b[39m\u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_data_3d)\u001b[39m==\u001b[39m\u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodified_label_data_3d)\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_data_3d)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m img_stack \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mstack(\u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimg_data_3d\u001b[39m.\u001b[39;49mvalues()), dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     99\u001b[0m img_mean, img_std \u001b[39m=\u001b[39m img_stack\u001b[39m.\u001b[39mmean(), img_stack\u001b[39m.\u001b[39mstd()\n\u001b[1;32m    101\u001b[0m label_stack \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(\u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_data_3d\u001b[39m.\u001b[39mvalues()), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "\n",
    "config_dict = DotDict({\n",
    "    'num_folds': 5,\n",
    "    'only_first_fold': True,                # If true do not contiue with training after the first fold\n",
    "    # 'fold_override': 0,\n",
    "    # 'checkpoint_epx': 0,\n",
    "\n",
    "    'use_mind': False,                      # If true use MIND features (https://pubmed.ncbi.nlm.nih.gov/22722056/)\n",
    "    'epochs': 40,\n",
    "\n",
    "    'batch_size': 8,\n",
    "    'val_batch_size': 1,\n",
    "    'use_2d_normal_to': 'HLA/SA',               # Can be None or 'D', 'H', 'W'. If not None 2D slices will be selected for training\n",
    "\n",
    "    'atlas_count': 1,                       # If three (noisy) labels per image are used specify three\n",
    "\n",
    "    'dataset': 'mmwhs',                 # The dataset prepared with our preprocessing scripts\n",
    "    'data_base_path': str(Path(THIS_SCRIPT_DIR, \"data/MMWHS\")),\n",
    "    'reg_state': None, # Registered (noisy) labels used in training. See prepare_data() for valid reg_states\n",
    "    'train_set_max_len': None,              # Length to cut of dataloader sample count\n",
    "    'crop_3d_region': None,        # W-dimension range in which 3D samples are cropped\n",
    "    'crop_2d_slices_gt_num_threshold': 0,   # Drop 2D slices if less than threshold pixels are positive\n",
    "\n",
    "    'lr': 0.01,\n",
    "    'use_scheduling': True,\n",
    "\n",
    "    'save_every': 200,\n",
    "    'mdl_save_prefix': 'data/models',\n",
    "\n",
    "    'debug': False,\n",
    "    'wandb_mode': 'online',                         # e.g. online, disabled. Use weights and biases online logging\n",
    "    'do_sweep': True,                                # Run multiple trainings with varying config values defined in sweep_config_dict below\n",
    "\n",
    "    # For a snapshot file: dummy-a2p2z76CxhCtwLJApfe8xD_fold0_epx0\n",
    "    'checkpoint_name': None,                          # Training snapshot name, e.g. dummy-a2p2z76CxhCtwLJApfe8xD\n",
    "    'fold_override': None,                            # Training fold, e.g. 0\n",
    "    'checkpoint_epx': None,                           # Training epx, e.g. 0\n",
    "\n",
    "    'do_plot': False,                                 # Generate plots (debugging purpose)\n",
    "    'save_dp_figures': False,                         # Plot data parameter value distribution\n",
    "    'save_labels': True,                              # Store training labels alongside data parameter values inside the training snapshot\n",
    "\n",
    "    'device': 'cuda'\n",
    "})\n",
    "\n",
    "config = config_dict\n",
    "\n",
    "training_dataset = MMWHSDataset(\n",
    "    config.data_base_path,\n",
    "    state=\"training\",\n",
    "    load_func=load_data,\n",
    "    extract_slice_func=extract_2d_data,\n",
    "    use_2d_normal_to=config.use_2d_normal_to, # Use 2D slices cut normal to D,H,>W< dimensions\n",
    "    do_resample=False, # Prior to cropping, resample image?\n",
    "    crop_3d_region=None, # Crop or pad the images to these dimensions\n",
    "    pre_interpolation_factor=1., # When getting the data, resize the data by this factor\n",
    "    ensure_labeled_pairs=True, # Only use fully labelled images (segmentation label available)\n",
    "    modality='mr',\n",
    "    do_align_global=True,\n",
    "    device=config.device,\n",
    "    debug=config.debug\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b5a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c246dab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "50e8264c9cb9bb8a6cada87af39a6b7aa8c2638398580ca823279198d429a8d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
