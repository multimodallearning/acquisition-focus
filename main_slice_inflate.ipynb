{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1dcc3d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "os.environ['MMWHS_CACHE_PATH'] = str(Path('.', '.cache'))\n",
    "\n",
    "from meidic_vtach_utils.run_on_recommended_cuda import get_cuda_environ_vars as get_vars\n",
    "os.environ.update(get_vars('*'))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.cuda.amp as amp\n",
    "\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import nibabel as nib\n",
    "\n",
    "from slice_inflate.datasets.mmwhs_dataset import MMWHSDataset, load_data, extract_2d_data\n",
    "from slice_inflate.utils.common_utils import DotDict, get_script_dir, in_notebook\n",
    "from slice_inflate.utils.torch_utils import reset_determinism, ensure_dense, \\\n",
    "    get_batch_dice_over_all, get_batch_score_per_label, save_model, \\\n",
    "    reduce_label_scores_epoch, get_test_func_all_parameters_updated\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from slice_inflate.datasets.align_mmwhs import cut_slice\n",
    "from slice_inflate.utils.log_utils import get_global_idx, log_label_metrics, log_oa_metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader\n",
    "from slice_inflate.losses.dice_loss import DC_and_CE_loss\n",
    "\n",
    "from mdl_seg_class.metrics import dice3d, hausdorff3d\n",
    "import numpy as np\n",
    "\n",
    "from slice_inflate.models.generic_UNet_opt_skip_connections import Generic_UNet\n",
    "import dill\n",
    "\n",
    "import einops as eo\n",
    "\n",
    "THIS_SCRIPT_DIR = get_script_dir()\n",
    "\n",
    "PROJECT_NAME = \"slice_inflate\"\n",
    "\n",
    "training_dataset, test_dataset = None, None\n",
    "test_all_parameters_updated = get_test_func_all_parameters_updated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ef0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(Path(THIS_SCRIPT_DIR, 'config_dict.json'), 'r') as f:\n",
    "    config_dict = DotDict(json.load(f))\n",
    "\n",
    "def prepare_data(config):\n",
    "    training_dataset = MMWHSDataset(\n",
    "        config.data_base_path,\n",
    "        state=config.state,\n",
    "        load_func=load_data,\n",
    "        extract_slice_func=extract_2d_data,\n",
    "        modality=config.modality,\n",
    "        do_align_global=True,\n",
    "        do_resample=False, # Prior to cropping, resample image?\n",
    "        crop_3d_region=None, # Crop or pad the images to these dimensions\n",
    "        fov_mm=config.fov_mm,\n",
    "        fov_vox=config.fov_vox,\n",
    "        crop_around_3d_label_center=config.crop_around_3d_label_center,\n",
    "        pre_interpolation_factor=1., # When getting the data, resize the data by this factor\n",
    "        ensure_labeled_pairs=True, # Only use fully labelled images (segmentation label available)\n",
    "        use_2d_normal_to=config.use_2d_normal_to, # Use 2D slices cut normal to D,H,>W< dimensions\n",
    "        crop_around_2d_label_center=config.crop_around_2d_label_center,\n",
    "        max_load_3d_num=config.max_load_3d_num,\n",
    "\n",
    "        augment_angle_std=5,\n",
    "\n",
    "        device=config.device,\n",
    "        debug=config.debug\n",
    "    )\n",
    "\n",
    "    return training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42c75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_test_once_only = not (config_dict.test_only_and_output_to in [\"\", None])\n",
    "\n",
    "if training_dataset is None:\n",
    "    train_config = DotDict(config_dict.copy())\n",
    "    if run_test_once_only:\n",
    "        train_config['state'] = 'empty'\n",
    "    training_dataset = prepare_data(train_config)\n",
    "\n",
    "if test_dataset is None:\n",
    "    test_config = DotDict(config_dict.copy())\n",
    "    test_config['state'] = 'test'\n",
    "    test_dataset = prepare_data(test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c10a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    training_dataset.train(augment=True)\n",
    "    training_dataset.self_attributes['augment_angle_std'] = 1\n",
    "    print(\"do_augment\", training_dataset.do_augment)\n",
    "    for sample in [training_dataset[idx] for idx in range(20)]:\n",
    "        fig = plt.figure(figsize=(16., 1.))\n",
    "\n",
    "        show_row = [\n",
    "            # cut_slice(sample['image']),\n",
    "            cut_slice(sample['label'].unsqueeze(0)).argmax(1).squeeze(),\n",
    "\n",
    "            # sample['sa_image_slc'],\n",
    "            sample['sa_label_slc'].unsqueeze(0).argmax(1).squeeze(),\n",
    "\n",
    "            # sample['hla_image_slc'],\n",
    "            sample['hla_label_slc'].unsqueeze(0).argmax(1).squeeze(),\n",
    "        ]\n",
    "\n",
    "        show_row = [sh.cpu() for sh in show_row]\n",
    "\n",
    "        grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "            nrows_ncols=(1, len(show_row)),  # creates 2x2 grid of axes\n",
    "            axes_pad=0.0,  # pad between axes in inch.\n",
    "        )\n",
    "\n",
    "        for ax, im in zip(grid, show_row):\n",
    "            ax.imshow(im, cmap='gray', interpolation='none')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac2bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    training_dataset.train(augment=True)\n",
    "    training_dataset.self_attributes['augment_angle_std'] = 1\n",
    "    print(\"do_augment\", training_dataset.do_augment)\n",
    "\n",
    "    train_dataloader = DataLoader(training_dataset, batch_size=config_dict.batch_size,\n",
    "        pin_memory=False, drop_last=False,\n",
    "        collate_fn=training_dataset.get_efficient_augmentation_collate_fn()\n",
    "    )\n",
    "    training_dataset.set_augment_at_collate(True)\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        fig = plt.figure(figsize=(16., 1.))\n",
    "\n",
    "        show_row = \\\n",
    "            [sh for sh in cut_slice(batch['label']).argmax(1).squeeze()] + \\\n",
    "            [sh for sh in batch['sa_label_slc'].argmax(1).squeeze()] + \\\n",
    "            [sh for sh in batch['hla_label_slc'].argmax(1).squeeze()]\n",
    "        \n",
    "        show_row = [sh.cpu() for sh in show_row]\n",
    "\n",
    "        grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "            nrows_ncols=(1, len(show_row)),  # creates 2x2 grid of axes\n",
    "            axes_pad=0.0,  # pad between axes in inch.\n",
    "        )\n",
    "\n",
    "        for ax, im in zip(grid, show_row):\n",
    "            ax.imshow(im, cmap='gray', interpolation='none')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a7023d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2dbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    training_dataset.train()\n",
    "\n",
    "    training_dataset.self_attributes['augment_angle_std'] = 5\n",
    "    print(\"do_augment\", training_dataset.do_augment)\n",
    "    for sample_idx in range(20):\n",
    "        lbl, sa_label, hla_label = torch.zeros(128,128), torch.zeros(128,128), torch.zeros(128,128)\n",
    "        for augment_idx in range(15):\n",
    "            sample = training_dataset[sample_idx]\n",
    "            nib.save(nib.Nifti1Image(sample['label'].cpu().numpy(), affine=torch.eye(4).numpy()), f'out{sample_idx}.nii.gz')\n",
    "            lbl += cut_slice(sample['label']).cpu()\n",
    "            sa_label += sample['sa_label_slc'].cpu()\n",
    "            hla_label += sample['hla_label_slc'].cpu()\n",
    "\n",
    "        fig = plt.figure(figsize=(16., 4.))\n",
    "        grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "            nrows_ncols=(1, 3),  # creates 2x2 grid of axes\n",
    "            axes_pad=0.0,  # pad between axes in inch.\n",
    "        )\n",
    "\n",
    "        show_row = [\n",
    "            lbl, sa_label, hla_label\n",
    "        ]\n",
    "\n",
    "        for ax, im in zip(grid, show_row):\n",
    "            ax.imshow(im, cmap='magma', interpolation='none')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6850a3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    training_dataset.train(augment=False)\n",
    "    training_dataset.self_attributes['augment_angle_std'] = 2\n",
    "    print(training_dataset.do_augment)\n",
    "\n",
    "    lbl, sa_label, hla_label = torch.zeros(128,128), torch.zeros(128,128), torch.zeros(128,128)\n",
    "    for tr_idx in range(len(training_dataset)):\n",
    "        sample = training_dataset[tr_idx]\n",
    "\n",
    "        lbl += cut_slice(sample['label']).cpu()\n",
    "        sa_label += sample['sa_label_slc'].cpu()\n",
    "        hla_label += sample['hla_label_slc'].cpu()\n",
    "\n",
    "    fig = plt.figure(figsize=(16., 4.))\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "        nrows_ncols=(1, 3),  # creates 2x2 grid of axes\n",
    "        axes_pad=0.0,  # pad between axes in inch.\n",
    "    )\n",
    "\n",
    "    show_row = [\n",
    "        lbl, sa_label, hla_label\n",
    "    ]\n",
    "\n",
    "    for ax, im in zip(grid, show_row):\n",
    "        ax.imshow(im, cmap='magma', interpolation='none')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725fea7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591fab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlendowskiAE(torch.nn.Module):\n",
    "\n",
    "    class ConvBlock(torch.nn.Module):\n",
    "        def __init__(self, in_channels: int, out_channels_list: list, strides_list: list, kernels_list:list=None, paddings_list:list=None):\n",
    "            super().__init__()\n",
    "\n",
    "            ops = []\n",
    "            in_channels = [in_channels] + out_channels_list[:-1]\n",
    "            if kernels_list is None:\n",
    "                kernels_list = [3] * len(out_channels_list)\n",
    "            if paddings_list is None:\n",
    "                paddings_list = [1] * len(out_channels_list)\n",
    "\n",
    "            for op_idx in range(len(out_channels_list)):\n",
    "                ops.append(torch.nn.Conv3d(\n",
    "                    in_channels[op_idx],\n",
    "                    out_channels_list[op_idx],\n",
    "                    kernel_size=kernels_list[op_idx],\n",
    "                    stride=strides_list[op_idx],\n",
    "                    padding=paddings_list[op_idx]\n",
    "                ))\n",
    "                ops.append(torch.nn.BatchNorm3d(out_channels_list[op_idx]))\n",
    "                ops.append(torch.nn.LeakyReLU())\n",
    "\n",
    "            self.block = torch.nn.Sequential(*ops)\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.block(x)\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, decoder_in_channels=2, debug_mode=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.debug_mode = debug_mode\n",
    "\n",
    "        self.first_layer_encoder = self.ConvBlock(in_channels, out_channels_list=[8], strides_list=[1])\n",
    "        self.first_layer_decoder = self.ConvBlock(8, out_channels_list=[8,out_channels], strides_list=[1,1])\n",
    "\n",
    "        self.second_layer_encoder = self.ConvBlock(8, out_channels_list=[20,20,20], strides_list=[2,1,1])\n",
    "        self.second_layer_decoder = self.ConvBlock(20, out_channels_list=[8], strides_list=[1])\n",
    "\n",
    "        self.third_layer_encoder = self.ConvBlock(20, out_channels_list=[40,40,40], strides_list=[2,1,1])\n",
    "        self.third_layer_decoder = self.ConvBlock(40, out_channels_list=[20], strides_list=[1])\n",
    "\n",
    "        self.fourth_layer_encoder = self.ConvBlock(40, out_channels_list=[60,60,60], strides_list=[2,1,1])\n",
    "        self.fourth_layer_decoder = self.ConvBlock(decoder_in_channels, out_channels_list=[40], strides_list=[1])\n",
    "\n",
    "        self.deepest_layer = torch.nn.Sequential(\n",
    "            self.ConvBlock(60, out_channels_list=[60,40,20], strides_list=[2,1,1]),\n",
    "            torch.nn.Conv3d(20, 2, kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            self.first_layer_encoder,\n",
    "            self.second_layer_encoder,\n",
    "            self.third_layer_encoder,\n",
    "            self.fourth_layer_encoder,\n",
    "        )\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Upsample(scale_factor=2),\n",
    "            self.fourth_layer_decoder,\n",
    "            torch.nn.Upsample(scale_factor=2),\n",
    "            self.third_layer_decoder,\n",
    "            torch.nn.Upsample(scale_factor=2),\n",
    "            self.second_layer_decoder,\n",
    "            torch.nn.Upsample(scale_factor=2),\n",
    "            self.first_layer_decoder,\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        h = self.deepest_layer(h)\n",
    "        # h = debug_forward_pass(self.encoder, x, STEP_MODE=False)\n",
    "        # h = debug_forward_pass(self.deepest_layer, h, STEP_MODE=False)\n",
    "        return h\n",
    "\n",
    "    def decode(self, z):\n",
    "        if self.debug_mode:\n",
    "            return debug_forward_pass(self.decoder, z, STEP_MODE=False)\n",
    "        else:\n",
    "            return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = torch.nn.functional.instance_norm(x)\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z), z\n",
    "\n",
    "\n",
    "\n",
    "class BlendowskiVAE(BlendowskiAE):\n",
    "    def __init__(self, std_max=10.0, epoch=0, epoch_reach_std_max=250, *args, **kwargs):\n",
    "        kwargs['decoder_in_channels'] = 1\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.deepest_layer_upstream = self.ConvBlock(60, out_channels_list=[60,40,20], strides_list=[2,1,1])\n",
    "        self.deepest_layer_downstream = nn.ModuleList([\n",
    "            torch.nn.Conv3d(20, 1, kernel_size=1, stride=1, padding=0),\n",
    "            torch.nn.Conv3d(20, 1, kernel_size=1, stride=1, padding=0)\n",
    "        ])\n",
    "\n",
    "        self.log_var_scale = nn.Parameter(torch.Tensor([0.0]))\n",
    "        self.epoch = epoch\n",
    "        self.epoch_reach_std_max = epoch_reach_std_max\n",
    "        self.std_max = std_max\n",
    "\n",
    "    def set_epoch(self, epoch):\n",
    "        self.epoch = epoch\n",
    "\n",
    "    def get_std_max(self):\n",
    "        SIGMOID_XMIN, SIGMOID_XMAX = -8.0, 8.0\n",
    "        s_x = (SIGMOID_XMAX-SIGMOID_XMIN) / (self.epoch_reach_std_max - 0) * self.epoch + SIGMOID_XMIN\n",
    "        std_max = torch.sigmoid(torch.tensor(s_x)) * self.std_max\n",
    "        return std_max\n",
    "\n",
    "    def sample_z(self, mean, std):\n",
    "        q = torch.distributions.Normal(mean, std)\n",
    "        return q.rsample() # Caution, dont use torch.normal(mean=mean, std=std). Gradients are not backpropagated\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        h = self.deepest_layer_upstream(h)\n",
    "        mean = self.deepest_layer_downstream[0](h)\n",
    "        log_var = self.deepest_layer_downstream[1](h)\n",
    "        return mean, log_var\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.encode(x)\n",
    "        std = torch.exp(log_var/2)\n",
    "        std = std.clamp(min=1e-10, max=self.get_std_max())\n",
    "        z = self.sample_z(mean=mean, std=std)\n",
    "        return self.decode(z), (z, mean, std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3379245",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# x = torch.zeros(1,8,128,128,128)\n",
    "# bae = BlendowskiAE(in_channels=8, out_channels=8)\n",
    "\n",
    "# y, z = bae(x)\n",
    "\n",
    "# print(\"BAE\")\n",
    "# print(\"x\", x.shape)\n",
    "# print(\"z\", z.shape)\n",
    "# print(\"y\", y.shape)\n",
    "# print()\n",
    "\n",
    "# bvae = BlendowskiVAE(in_channels=8, out_channels=8)\n",
    "\n",
    "# y, z = bvae(x)\n",
    "\n",
    "# print(\"BVAE\")\n",
    "# print(\"x\", x.shape)\n",
    "# print(\"z\", z.shape)\n",
    "# print(\"y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e5daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BlendowskiVAE(in_channels=6, out_channels=6)\n",
    "# model.cuda()\n",
    "# with torch.no_grad():\n",
    "#     smp = torch.nn.functional.one_hot(training_dataset[1]['label'], 6).unsqueeze(0).permute([0,4,1,2,3]).float().cuda()\n",
    "# y, _ = model(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e6f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nan_hook(self, inp, output):\n",
    "#     if not isinstance(output, tuple):\n",
    "#         outputs = [output]\n",
    "#     else:\n",
    "#         outputs = output\n",
    "\n",
    "#     for i, out in enumerate(outputs):\n",
    "#         nan_mask = torch.isnan(out)\n",
    "#         if nan_mask.any():\n",
    "#             print(\"In\", self.__class__.__name__)\n",
    "#             raise RuntimeError(f\"Found NAN in output {i} at indices: \", nan_mask.nonzero(), \"where:\", out[nan_mask.nonzero()[:, 0].unique(sorted=True)])\n",
    "\n",
    "def get_model(config, dataset_len, num_classes, THIS_SCRIPT_DIR, _path=None, device='cpu', load_model_only=False, encoder_training_only=False):\n",
    "    if not _path is None:\n",
    "        _path = Path(THIS_SCRIPT_DIR).joinpath(_path).resolve()\n",
    "\n",
    "    if config.model_type == 'vae':\n",
    "        model = BlendowskiVAE(std_max=10.0, epoch=0, epoch_reach_std_max=250,\n",
    "            in_channels=num_classes, out_channels=num_classes)\n",
    "\n",
    "    elif config.model_type == 'ae':\n",
    "        model = BlendowskiAE(in_channels=num_classes, out_channels=num_classes)\n",
    "    elif 'unet' in config.model_type:\n",
    "        init_dict_path = Path(THIS_SCRIPT_DIR, \"./slice_inflate/models/nnunet_init_dict_128_128_128.pkl\")\n",
    "        with open(init_dict_path, 'rb') as f:\n",
    "            init_dict = dill.load(f)\n",
    "        init_dict['num_classes'] = num_classes\n",
    "        init_dict['deep_supervision'] = False\n",
    "        init_dict['final_nonlin'] = torch.nn.Identity()\n",
    "        use_skip_connections = True if not 'wo-skip' in config.model_type else False\n",
    "        nnunet_model = Generic_UNet(**init_dict, use_skip_connections=use_skip_connections, use_onehot_input=True)\n",
    "\n",
    "        seg_outputs = list(filter(lambda elem: 'seg_outputs' in elem[0], nnunet_model.named_parameters()))\n",
    "        # Disable gradients of non-used deep supervision\n",
    "        for so_idx in range(len(seg_outputs)-1):\n",
    "            seg_outputs[so_idx][1].requires_grad = False\n",
    "        class InterfaceModel(torch.nn.Module):\n",
    "            def __init__(self, nnunet_model):\n",
    "                super().__init__()\n",
    "                self.nnunet_model = nnunet_model\n",
    "\n",
    "            def forward(self, x):\n",
    "                y_hat = self.nnunet_model(x)\n",
    "                if isinstance(y_hat, tuple):\n",
    "                    return y_hat[0], None\n",
    "                else:\n",
    "                    return y_hat, None\n",
    "\n",
    "        model = InterfaceModel(nnunet_model)\n",
    "\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    if _path and _path.is_dir():\n",
    "        model_dict = torch.load(_path.joinpath('model.pth'), map_location=device)\n",
    "        epx = model_dict.get('metadata', {}).get('epx', 0)\n",
    "        print(f\"Loading model from {_path}\")\n",
    "        print(model.load_state_dict(model_dict, strict=False))\n",
    "    else:\n",
    "        print(f\"Generating fresh '{type(model).__name__}' model.\")\n",
    "        epx = 0\n",
    "\n",
    "    if encoder_training_only:\n",
    "        decoder_modules = filter(lambda elem: 'decoder' in elem[0], model.named_modules())\n",
    "        for nmod in decoder_modules:\n",
    "            for param in nmod[1].parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    print(f\"Trainable param count model: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "    print(f\"Non-trainable param count model: {sum(p.numel() for p in model.parameters() if not p.requires_grad)}\")\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config.lr)\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', patience=20, threshold=0.01, threshold_mode='rel')\n",
    "\n",
    "    if _path and _path.is_dir() and not load_model_only:\n",
    "        print(f\"Loading optimizer, scheduler, scaler from {_path}\")\n",
    "        optimizer.load_state_dict(torch.load(_path.joinpath('optimizer.pth'), map_location=device))\n",
    "        scheduler.load_state_dict(torch.load(_path.joinpath('scheduler.pth'), map_location=device))\n",
    "        scaler.load_state_dict(torch.load(_path.joinpath('scaler.pth'), map_location=device))\n",
    "\n",
    "    else:\n",
    "        print(f\"Generating fresh optimizer, scheduler, scaler.\")\n",
    "\n",
    "    training_dataset.sa_atm.to(device)\n",
    "    training_dataset.hla_atm.to(device)\n",
    "    optimizer.add_param_group(dict(params=training_dataset.sa_atm.parameters()))\n",
    "    optimizer.add_param_group(dict(params=training_dataset.hla_atm.parameters()))\n",
    "\n",
    "    # for submodule in model.modules():\n",
    "    #     submodule.register_forward_hook(nan_hook)\n",
    "\n",
    "    return (model, optimizer, scheduler, scaler), epx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_input(batch, config, num_classes):\n",
    "    W_TARGET_LEN = 128\n",
    "    b_hla_slc_seg = batch['hla_label_slc']\n",
    "    b_sa_slc_seg = batch['sa_label_slc']\n",
    "    b_input = torch.cat([b_hla_slc_seg, b_sa_slc_seg], dim=-1)\n",
    "    b_input = torch.cat([b_input] * int(W_TARGET_LEN/b_input.shape[-1]), dim=-1) # Stack data hla/sa next to each other\n",
    "\n",
    "    b_seg = batch['label']\n",
    "\n",
    "    b_input = b_input.to(device=config.device)\n",
    "    b_seg = b_seg.to(device=config.device)\n",
    "\n",
    "    return b_input.float(), b_seg\n",
    "\n",
    "def inference_wrap(model, seg):\n",
    "    with torch.inference_mode():\n",
    "        b_seg = seg.unsqueeze(0).unsqueeze(0).float()\n",
    "        b_out = model(b_seg)[0]\n",
    "        b_out = b_out.argmax(1)\n",
    "        return b_out\n",
    "\n",
    "\n",
    "\n",
    "def gaussian_likelihood(y_hat, log_var_scale, y_target):\n",
    "    B,C,*_ = y_hat.shape\n",
    "    scale = torch.exp(log_var_scale/2)\n",
    "    dist = torch.distributions.Normal(y_hat, scale)\n",
    "\n",
    "    # measure prob of seeing image under p(x|z)\n",
    "    log_pxz = dist.log_prob(y_target)\n",
    "\n",
    "    # GLH\n",
    "    return log_pxz\n",
    "\n",
    "\n",
    "\n",
    "def kl_divergence(z, mean, std):\n",
    "    # See https://towardsdatascience.com/variational-autoencoder-demystified-with-pytorch-implementation-3a06bee395ed\n",
    "    B,*_ = z.shape\n",
    "    p = torch.distributions.Normal(torch.zeros_like(mean), torch.ones_like(std))\n",
    "    q = torch.distributions.Normal(mean, std)\n",
    "\n",
    "    log_qzx = q.log_prob(z)\n",
    "    log_pz = p.log_prob(z)\n",
    "\n",
    "    # KL divergence\n",
    "    kl = (log_qzx - log_pz)\n",
    "\n",
    "    # Reduce spatial dimensions\n",
    "    return kl.reshape(B,-1)\n",
    "\n",
    "\n",
    "\n",
    "def get_ae_loss_value(y_hat, y_target, class_weights):\n",
    "    return DC_and_CE_loss({}, {})(y_hat, y_target.argmax(1, keepdim=True))\n",
    "\n",
    "\n",
    "def get_vae_loss_value(y_hat, y_target, z, mean, std, class_weights, model):\n",
    "    recon_loss = get_ae_loss_value(y_hat, y_target, class_weights)#torch.nn.MSELoss()(y_hat, y_target)#gaussian_likelihood(y_hat, model.log_var_scale, y_target.float())\n",
    "    # recon_loss = eo.reduce(recon_loss, 'B C spatial -> B ()', 'mean')\n",
    "    kl = kl_divergence(z, mean, std)\n",
    "\n",
    "    elbo = (0.1*kl + recon_loss).mean()\n",
    "\n",
    "    return elbo\n",
    "\n",
    "def model_step(config, model, b_input, b_target, label_tags, class_weights, io_normalisation_values, autocast_enabled=False):\n",
    "    # b_input = b_input-io_normalisation_values['input_mean'].to(b_input.device)\n",
    "    # b_input = b_input/io_normalisation_values['input_std'].to(b_input.device)\n",
    "\n",
    "    ### Forward pass ###\n",
    "    with amp.autocast(enabled=autocast_enabled):\n",
    "        assert b_input.dim() == 5, \\\n",
    "            f\"Input image for model must be {5}D: BxCxSPATIAL but is {b_input.shape}\"\n",
    "\n",
    "        if config.model_type == 'vae':\n",
    "            y_hat, (z, mean, std) = model(b_input)\n",
    "        elif config.model_type in ['ae', 'unet', 'unet-wo-skip']:\n",
    "            y_hat, _ = model(b_input)\n",
    "        else:\n",
    "            raise ValueError\n",
    "        # Reverse normalisation to outputs\n",
    "        # y_hat = y_hat*io_normalisation_values['target_std'].to(b_input.device)\n",
    "        # y_hat = y_hat+io_normalisation_values['target_mean'].to(b_input.device)\n",
    "\n",
    "        ### Calculate loss ###\n",
    "        assert y_hat.dim() == 5, \\\n",
    "            f\"Input shape for loss must be {5}D: BxNUM_CLASSESxSPATIAL but is {y_hat.shape}\"\n",
    "        assert b_target.dim() == 5, \\\n",
    "            f\"Target shape for loss must be {5}D: BxNUM_CLASSESxSPATIAL but is {b_target.shape}\"\n",
    "\n",
    "        if \"vae\" in type(model).__name__.lower():\n",
    "            loss = get_vae_loss_value(y_hat, b_target.float(), z, mean, std, class_weights, model)\n",
    "        else:\n",
    "            loss = get_ae_loss_value(y_hat, b_target.float(), class_weights)\n",
    "\n",
    "    return y_hat, loss\n",
    "\n",
    "\n",
    "\n",
    "def epoch_iter(epx, global_idx, config, model, dataset, dataloader, class_weights, fold_postfix, phase='train',\n",
    "    autocast_enabled=False, optimizer=None, scaler=None, store_net_output_to=None):\n",
    "    PHASES = ['train', 'val', 'test']\n",
    "    assert phase in ['train', 'val', 'test'], f\"phase must be one of {PHASES}\"\n",
    "\n",
    "    epx_losses = []\n",
    "    label_scores_epoch = {}\n",
    "    seg_metrics_nanmean = {}\n",
    "    seg_metrics_std = {}\n",
    "    seg_metrics_nanmean_oa = {}\n",
    "    seg_metrics_std_oa = {}\n",
    "\n",
    "    if phase == 'train':\n",
    "        model.train()\n",
    "        dataset.train(use_modified=False)\n",
    "    else:\n",
    "        model.eval()\n",
    "        dataset.eval()\n",
    "\n",
    "    if isinstance(model, BlendowskiVAE):\n",
    "        model.set_epoch(epx)\n",
    "\n",
    "    for batch_idx, batch in tqdm(enumerate(dataloader), desc=phase, total=len(dataloader)):\n",
    "        b_input, b_seg = get_model_input(batch, config, len(dataset.label_tags))\n",
    "        if phase == 'train':\n",
    "            optimizer.zero_grad()\n",
    "            y_hat, loss = model_step(config, model, b_input, b_seg, dataset.label_tags, class_weights, dataset.io_normalisation_values, autocast_enabled)\n",
    "            scaler.scale(loss).backward()\n",
    "            # test_all_parameters_updated(model)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                y_hat, loss = model_step(config, model, b_input, b_seg, dataset.label_tags, class_weights, dataset.io_normalisation_values, autocast_enabled)\n",
    "\n",
    "        epx_losses.append(loss.item())\n",
    "\n",
    "        pred_seg = y_hat.argmax(1)\n",
    "\n",
    "        # Taken from nibabel nifti1.py\n",
    "        RZS = batch['sa_affine'][0][:3,:3].detach().cpu().numpy()\n",
    "        nifti_zooms = np.sqrt(np.sum(RZS * RZS, axis=0))\n",
    "\n",
    "        # Calculate fast dice score\n",
    "        b_dice = dice3d(\n",
    "            eo.rearrange(torch.nn.functional.one_hot(pred_seg, len(training_dataset.label_tags)), 'b d h w oh -> b oh d h w'),\n",
    "            b_seg,\n",
    "            one_hot_torch_style=False\n",
    "        )\n",
    "        label_scores_epoch = get_batch_score_per_label(label_scores_epoch, 'dice',\n",
    "            b_dice, training_dataset.label_tags, exclude_bg=True)\n",
    "\n",
    "        if epx % 20 == 0 and epx > 0:\n",
    "            b_hd = hausdorff3d(b_input, b_seg, spacing_mm=tuple(nifti_zooms), percent=100)\n",
    "            label_scores_epoch = get_batch_score_per_label(label_scores_epoch, 'hd',\n",
    "                b_hd, training_dataset.label_tags, exclude_bg=True)\n",
    "\n",
    "            b_hd95 = hausdorff3d(b_input, b_seg, spacing_mm=tuple(nifti_zooms), percent=95)\n",
    "            label_scores_epoch = get_batch_score_per_label(label_scores_epoch, 'hd95',\n",
    "                b_hd95, training_dataset.label_tags, exclude_bg=True)\n",
    "\n",
    "        if store_net_output_to not in [\"\", None]:\n",
    "            store_path = Path(store_net_output_to, f\"output_batch{batch_idx}.pth\")\n",
    "            store_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "            torch.save(dict(batch=batch, input=b_input, output=y_hat, target=b_seg), store_path)\n",
    "\n",
    "        if config.debug: break\n",
    "\n",
    "    (seg_metrics_nanmean,\n",
    "     seg_metrics_std,\n",
    "     seg_metrics_nanmean_oa,\n",
    "     seg_metrics_std_oa) = reduce_label_scores_epoch(label_scores_epoch)\n",
    "\n",
    "    loss_mean = torch.tensor(epx_losses).mean()\n",
    "    ### Logging ###\n",
    "    print(f\"### {phase.upper()}\")\n",
    "\n",
    "    ### Log wandb data ###\n",
    "    log_id = f'losses/{phase}_loss{fold_postfix}'\n",
    "    log_val = loss_mean\n",
    "    wandb.log({log_id: log_val}, step=global_idx)\n",
    "    print(f'losses/{phase}_loss{fold_postfix}', log_val)\n",
    "\n",
    "    log_label_metrics(f\"scores/{phase}_mean\", fold_postfix, seg_metrics_nanmean, global_idx,\n",
    "        logger_selected_metrics=('dice', 'hd', 'hd95'), print_selected_metrics=('dice'))\n",
    "\n",
    "    log_label_metrics(f\"scores/{phase}_std\", fold_postfix, seg_metrics_std, global_idx,\n",
    "        logger_selected_metrics=('dice', 'hd', 'hd95'), print_selected_metrics=())\n",
    "\n",
    "    log_oa_metrics(f\"scores/{phase}_mean_oa_exclude_bg\", fold_postfix, seg_metrics_nanmean_oa, global_idx,\n",
    "        logger_selected_metrics=('dice', 'hd', 'hd95'), print_selected_metrics=('dice', 'hd', 'hd95'))\n",
    "\n",
    "    log_oa_metrics(f\"scores/{phase}_std_oa_exclude_bg\", fold_postfix, seg_metrics_std_oa, global_idx,\n",
    "        logger_selected_metrics=('dice', 'hd', 'hd95'), print_selected_metrics=())\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    return loss_mean\n",
    "\n",
    "\n",
    "\n",
    "def run_dl(run_name, config, training_dataset, test_dataset):\n",
    "    reset_determinism()\n",
    "\n",
    "    # Configure folds\n",
    "    if config.num_folds < 1:\n",
    "        train_idxs = range(training_dataset.__len__(use_2d_override=False))\n",
    "        val_idxs = []\n",
    "        fold_idx = -1\n",
    "        fold_iter = ([fold_idx, (train_idxs, val_idxs)],)\n",
    "\n",
    "    else:\n",
    "        kf = KFold(n_splits=config.num_folds)\n",
    "        fold_iter = enumerate(kf.split(range(training_dataset.__len__(use_2d_override=False))))\n",
    "\n",
    "        if config.get('fold_override', None):\n",
    "            selected_fold = config.get('fold_override', 0)\n",
    "            fold_iter = list(fold_iter)[selected_fold:selected_fold+1]\n",
    "\n",
    "    fold_means_no_bg = []\n",
    "\n",
    "    for fold_idx, (train_idxs, val_idxs) in fold_iter:\n",
    "        fold_postfix = f'_fold{fold_idx}' if fold_idx != -1 else \"\"\n",
    "\n",
    "        best_quality_metric = 1.e16\n",
    "        train_idxs = torch.tensor(train_idxs)\n",
    "        val_idxs = torch.tensor(val_idxs)\n",
    "        val_ids = training_dataset.switch_3d_identifiers(val_idxs)\n",
    "\n",
    "        print(f\"Will run validation with these 3D samples (#{len(val_ids)}):\", sorted(val_ids))\n",
    "\n",
    "        ### Add train sampler and dataloaders ##\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_idxs)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_idxs)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(range(len(test_dataset)))\n",
    "\n",
    "        if not run_test_once_only:\n",
    "            train_dataloader = DataLoader(training_dataset, batch_size=config.batch_size,\n",
    "                sampler=train_subsampler, pin_memory=False, drop_last=False,\n",
    "                collate_fn=training_dataset.get_efficient_augmentation_collate_fn()\n",
    "            )\n",
    "            training_dataset.set_augment_at_collate(True)\n",
    "\n",
    "            val_dataloader = DataLoader(training_dataset, batch_size=config.val_batch_size,\n",
    "                sampler=val_subsampler, pin_memory=False, drop_last=False\n",
    "            )\n",
    "\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=config.val_batch_size,\n",
    "            sampler=test_subsampler, pin_memory=False, drop_last=False\n",
    "        )\n",
    "\n",
    "        # Load from checkpoint, if any\n",
    "        chk_path = config.checkpoint_path if 'checkpoint_path' in config else None\n",
    "\n",
    "        ### Get model, data parameters, optimizers for model and data parameters, as well as grad scaler ###\n",
    "        (model, optimizer, scheduler, scaler), epx_start = get_model(config, len(training_dataset), len(training_dataset.label_tags),\n",
    "            THIS_SCRIPT_DIR=THIS_SCRIPT_DIR, _path=chk_path, device=config.device, load_model_only=False, encoder_training_only=config.encoder_training_only)\n",
    "\n",
    "        all_bn_counts = torch.zeros([len(training_dataset.label_tags)], device='cpu')\n",
    "\n",
    "        # for bn_counts in training_dataset.bincounts_3d.values():\n",
    "        #     all_bn_counts += bn_counts\n",
    "\n",
    "        # class_weights = 1 / (all_bn_counts).float().pow(.35)\n",
    "        # class_weights /= class_weights.mean()\n",
    "\n",
    "        # class_weights = class_weights.to(device=config.device)\n",
    "        class_weights = None\n",
    "\n",
    "        autocast_enabled = 'cuda' in config.device\n",
    "\n",
    "        for epx in range(epx_start, config.epochs):\n",
    "            global_idx = get_global_idx(fold_idx, epx, config.epochs)\n",
    "            # Log the epoch idx per fold - so we can recover the diagram by setting\n",
    "            # ref_epoch_idx as x-axis in wandb interface\n",
    "            print(f\"### Log epoch {epx}\")\n",
    "            wandb.log({\"ref_epoch_idx\": epx}, step=global_idx)\n",
    "\n",
    "            if not run_test_once_only:\n",
    "                train_loss = epoch_iter(epx, global_idx, config, model, training_dataset, train_dataloader, class_weights, fold_postfix,\n",
    "                    phase='train', autocast_enabled=autocast_enabled, optimizer=optimizer, scaler=scaler, store_net_output_to=None)\n",
    "\n",
    "                val_loss = epoch_iter(epx, global_idx, config, model, training_dataset, val_dataloader, class_weights, fold_postfix,\n",
    "                    phase='val', autocast_enabled=autocast_enabled, optimizer=None, scaler=None, store_net_output_to=None)\n",
    "\n",
    "            quality_metric = test_loss = epoch_iter(epx, global_idx, config, model, test_dataset, test_dataloader, class_weights, fold_postfix,\n",
    "                phase='test', autocast_enabled=autocast_enabled, optimizer=None, scaler=None, store_net_output_to=config.test_only_and_output_to)\n",
    "\n",
    "\n",
    "            if run_test_once_only:\n",
    "                break\n",
    "\n",
    "            ###  Scheduler management ###\n",
    "            if config.use_scheduling:\n",
    "                scheduler.step(quality_metric)\n",
    "\n",
    "            wandb.log({f'training/scheduler_lr': scheduler.optimizer.param_groups[0]['lr']}, step=global_idx)\n",
    "            print()\n",
    "\n",
    "            # Save model\n",
    "            if config.save_every is None:\n",
    "                pass\n",
    "\n",
    "            elif config.save_every == 'best':\n",
    "                if quality_metric < best_quality_metric:\n",
    "                    best_quality_metric = quality_metric\n",
    "                    save_path = f\"{config.mdl_save_prefix}/{wandb.run.name}{fold_postfix}_best\"\n",
    "                    save_model(\n",
    "                        Path(THIS_SCRIPT_DIR, save_path),\n",
    "                        epx=epx,\n",
    "                        loss=train_loss,\n",
    "                        model=model,\n",
    "                        optimizer=optimizer,\n",
    "                        scheduler=scheduler,\n",
    "                        scaler=scaler)\n",
    "\n",
    "            elif (epx % config.save_every == 0) or (epx+1 == config.epochs):\n",
    "                save_path = f\"{config.mdl_save_prefix}/{wandb.run.name}{fold_postfix}_epx{epx}\"\n",
    "                save_model(\n",
    "                    Path(THIS_SCRIPT_DIR, save_path),\n",
    "                    model=model,\n",
    "                    optimizer=optimizer,\n",
    "                    scheduler=scheduler,\n",
    "                    scaler=scaler)\n",
    "\n",
    "                # (model, optimizer, scheduler, scaler) = \\\n",
    "                #     get_model(\n",
    "                #         config, len(training_dataset),\n",
    "                #         len(training_dataset.label_tags),\n",
    "                #         THIS_SCRIPT_DIR=THIS_SCRIPT_DIR,\n",
    "                #         _path=_path, device=config.device)\n",
    "\n",
    "            # End of epoch loop\n",
    "\n",
    "            if config.debug or run_test_once_only:\n",
    "                break\n",
    "\n",
    "        # End of fold loop\n",
    "        if config.debug or run_test_once_only:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ae77b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# training_dataset.eval()\n",
    "# eval_dataloader = DataLoader(training_dataset, batch_size=20,  pin_memory=False, drop_last=False)\n",
    "\n",
    "# for large_batch in eval_dataloader:\n",
    "#     large_b_input = get_model_input(large_batch, config_dict, num_classes=len(training_dataset.label_tags))\n",
    "\n",
    "# input_mean, input_std = large_b_input[0].float().mean((0,-3,-2,-1), keepdim=True).cpu(), large_b_input[0].float().std((0,-3,-2,-1), keepdim=True).cpu()\n",
    "# target_mean, target_std = large_b_input[1].float().mean((0,-3,-2,-1), keepdim=True).cpu(), large_b_input[1].float().std((0,-3,-2,-1), keepdim=True).cpu()\n",
    "\n",
    "# print(input_mean.shape, input_std.shape)\n",
    "# print(target_mean.shape, target_std.shape)\n",
    "\n",
    "# torch.save(dict(input_mean=input_mean, input_std=input_std, target_mean=target_mean, target_std=target_std), \"io_normalisation_values.pth\")\n",
    "# sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d544a290",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Config overrides\n",
    "# config_dict['wandb_mode'] = 'disabled'\n",
    "# config_dict['debug'] = True\n",
    "# Model loading\n",
    "# config_dict['checkpoint_path'] = 'ethereal-serenity-1138'\n",
    "# config_dict['fold_override'] = 0\n",
    "\n",
    "# Define sweep override dict\n",
    "sweep_config_dict = dict(\n",
    "    method='grid',\n",
    "    metric=dict(goal='maximize', name='scores/val_dice_mean_left_atrium_fold0'),\n",
    "    parameters=dict(\n",
    "        # disturbance_mode=dict(\n",
    "        #     values=[\n",
    "        #        'LabelDisturbanceMode.AFFINE',\n",
    "        #     ]\n",
    "        # ),\n",
    "        # disturbance_strength=dict(\n",
    "        #     values=[0.1, 0.2, 0.5, 1.0, 2.0, 5.0]\n",
    "        # ),\n",
    "        # disturbed_percentage=dict(\n",
    "        #     values=[0.3, 0.6]\n",
    "        # ),\n",
    "        # data_param_mode=dict(\n",
    "        #     values=[\n",
    "        #         DataParamMode.INSTANCE_PARAMS,\n",
    "        #         DataParamMode.DISABLED,\n",
    "        #     ]\n",
    "        # ),\n",
    "        use_risk_regularization=dict(\n",
    "            values=[False, True]\n",
    "        ),\n",
    "        use_fixed_weighting=dict(\n",
    "            values=[False, True]\n",
    "        ),\n",
    "        # fixed_weight_min_quantile=dict(\n",
    "        #     values=[0.9, 0.8, 0.6, 0.4, 0.2, 0.0]\n",
    "        # ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_run():\n",
    "    with wandb.init(project=PROJECT_NAME, group=\"training\", job_type=\"train\",\n",
    "            config=config_dict, settings=wandb.Settings(start_method=\"thread\"),\n",
    "            mode=config_dict['wandb_mode']\n",
    "        ) as run:\n",
    "\n",
    "        run_name = run.name\n",
    "        print(\"Running\", run_name)\n",
    "        # training_dataset = prepare_data(config_dict)\n",
    "        config = wandb.config\n",
    "\n",
    "        run_dl(run_name, config, training_dataset, test_dataset)\n",
    "\n",
    "def sweep_run():\n",
    "    with wandb.init() as run:\n",
    "        run = wandb.init(\n",
    "            settings=wandb.Settings(start_method=\"thread\"),\n",
    "            mode=config_dict['wandb_mode']\n",
    "        )\n",
    "\n",
    "        run_name = run.name\n",
    "        print(\"Running\", run_name)\n",
    "        # training_dataset = prepare_data(config)\n",
    "        config = wandb.config\n",
    "\n",
    "        run_dl(run_name, config, training_dataset, test_dataset)\n",
    "\n",
    "if config_dict['do_sweep']:\n",
    "    # Integrate all config_dict entries into sweep_dict.parameters -> sweep overrides config_dict\n",
    "    cp_config_dict = copy.deepcopy(config_dict)\n",
    "    # cp_config_dict.update(copy.deepcopy(sweep_config_dict['parameters']))\n",
    "    for del_key in sweep_config_dict['parameters'].keys():\n",
    "        if del_key in cp_config_dict:\n",
    "            del cp_config_dict[del_key]\n",
    "    merged_sweep_config_dict = copy.deepcopy(sweep_config_dict)\n",
    "    # merged_sweep_config_dict.update(cp_config_dict)\n",
    "    for key, value in cp_config_dict.items():\n",
    "        merged_sweep_config_dict['parameters'][key] = dict(value=value)\n",
    "    # Convert enum values in parameters to string. They will be identified by their numerical index otherwise\n",
    "    for key, param_dict in merged_sweep_config_dict['parameters'].items():\n",
    "        if 'value' in param_dict and isinstance(param_dict['value'], Enum):\n",
    "            param_dict['value'] = str(param_dict['value'])\n",
    "        if 'values' in param_dict:\n",
    "            param_dict['values'] = [str(elem) if isinstance(elem, Enum) else elem for elem in param_dict['values']]\n",
    "\n",
    "        merged_sweep_config_dict['parameters'][key] = param_dict\n",
    "\n",
    "    sweep_id = wandb.sweep(merged_sweep_config_dict, project=PROJECT_NAME)\n",
    "    wandb.agent(sweep_id, function=sweep_run)\n",
    "\n",
    "else:\n",
    "    normal_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not in_notebook():\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf20fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do any postprocessing / visualization in notebook here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13ad7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "50e8264c9cb9bb8a6cada87af39a6b7aa8c2638398580ca823279198d429a8d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
