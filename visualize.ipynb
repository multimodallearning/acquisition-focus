{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ['MMWHS_CACHE_PATH'] = str(Path('.', '.cache'))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.cuda.amp as amp\n",
    "\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import nibabel as nib\n",
    "\n",
    "from slice_inflate.datasets.mmwhs_dataset import MMWHSDataset, load_data, extract_2d_data\n",
    "from slice_inflate.utils.common_utils import DotDict, get_script_dir\n",
    "from slice_inflate.utils.torch_utils import reset_determinism, ensure_dense, save_model\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from slice_inflate.datasets.align_mmwhs import cut_slice\n",
    "from slice_inflate.utils.log_utils import get_global_idx, log_label_metrics, log_oa_metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mdl_seg_class.metrics import dice3d\n",
    "import numpy as np\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "THIS_SCRIPT_DIR = get_script_dir()\n",
    "\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "from skimage import measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = Path(\"/share/data_supergrover1/weihsbach/shared_data/tmp/slice_inflate/data/output/worthy-resonance-122_best/\").glob(\"*.pth\")\n",
    "USE_EYE_AFFINE = True\n",
    "\n",
    "for pth_path in files:\n",
    "    data = torch.load(pth_path)\n",
    "    base_path = Path(pth_path.parent, f\"{data['batch']['id'][0]}\")\n",
    "    if USE_EYE_AFFINE:\n",
    "        sa_affine = np.eye(4)\n",
    "    else:\n",
    "        sa_affine = data['batch']['sa_affine'].squeeze(0)\n",
    "    nib.save(nib.Nifti1Image(data['input'].argmax(1).squeeze(0).cpu().int().numpy(), sa_affine), str(base_path)+\"_input.nii.gz\")\n",
    "    nib.save(nib.Nifti1Image(data['target'].argmax(1).squeeze(0).cpu().int().numpy(), sa_affine), str(base_path)+\"_target.nii.gz\")\n",
    "    nib.save(nib.Nifti1Image(data['output'].argmax(1).squeeze(0).cpu().int().numpy(), sa_affine), str(base_path)+\"_output.nii.gz\")\n",
    "    nib.save(nib.Nifti1Image(data['batch']['image'].squeeze(0).cpu().float().numpy(), sa_affine), str(base_path)+\"_corresponding_input_image.nii.gz\")\n",
    "    # hla_affine = data['batch']['hla_affine'].squeeze(0)\n",
    "    # D_slc, H_slc = data['batch']['hla_label_slc'].squeeze(0).shape\n",
    "    # nib.save(nib.Nifti1Image(data['batch']['hla_label_slc'].squeeze(0).view(1, D_slc, H_slc).cpu().float().numpy(), hla_affine), str(base_path)+\"_hla_label_slice.nii.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create meshes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = DotDict({\n",
    "    'num_folds': 5,\n",
    "    'only_first_fold': True,                # If true do not contiue with training after the first fold\n",
    "    # 'fold_override': 0,\n",
    "    # 'checkpoint_epx': 0,\n",
    "                   # If true use MIND features (https://pubmed.ncbi.nlm.nih.gov/22722056/)\n",
    "    'epochs': 500,\n",
    "\n",
    "    'batch_size': 4,\n",
    "    'val_batch_size': 1,\n",
    "    'modality': 'mr',\n",
    "    'use_2d_normal_to': None,               # Can be None or 'D', 'H', 'W'. If not None 2D slices will be selected for training\n",
    "\n",
    "    'dataset': 'mmwhs',                 # The dataset prepared with our preprocessing scripts\n",
    "    'data_base_path': str(Path(THIS_SCRIPT_DIR, \"data/MMWHS\")),\n",
    "    'reg_state': None, # Registered (noisy) labels used in training. See prepare_data() for valid reg_states\n",
    "    'train_set_max_len': None,              # Length to cut of dataloader sample count\n",
    "    'crop_around_3d_label_center': (128,128,128),\n",
    "    'crop_3d_region': ((0,128), (0,128), (0,128)),        # dimension range in which 3D samples are cropped\n",
    "    'crop_2d_slices_gt_num_threshold': 0,   # Drop 2D slices if less than threshold pixels are positive\n",
    "\n",
    "    'lr': 1e-3,\n",
    "    'use_scheduling': True,\n",
    "\n",
    "    'save_every': 'best',\n",
    "    'mdl_save_prefix': 'data/models',\n",
    "\n",
    "    'debug': False,\n",
    "    'wandb_mode': 'online',                         # e.g. online, disabled. Use weights and biases online logging\n",
    "    'do_sweep': False,                                # Run multiple trainings with varying config values defined in sweep_config_dict below\n",
    "\n",
    "    # For a snapshot file: dummy-a2p2z76CxhCtwLJApfe8xD_fold0_epx0\n",
    "    'checkpoint_name': None,                          # Training snapshot name, e.g. dummy-a2p2z76CxhCtwLJApfe8xD\n",
    "    'fold_override': None,                            # Training fold, e.g. 0\n",
    "    'checkpoint_epx': None,                           # Training epx, e.g. 0\n",
    "\n",
    "    'do_plot': False,                                 # Generate plots (debugging purpose)\n",
    "    'save_dp_figures': False,                         # Plot data parameter value distribution\n",
    "    'save_labels': True,                              # Store training labels alongside data parameter values inside the training snapshot\n",
    "\n",
    "    'device': 'cuda'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MMWHS train images and labels... (['mr'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15 images, 15 labels: 100%|██████████| 30/30 [00:13<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postprocessing 3D volumes\n",
      "Removed 0 3D images in postprocessing\n",
      "Equal image and label numbers: True (15)\n",
      "Data import finished.\n",
      "Dataloader will yield 3D samples\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(config):\n",
    "    training_dataset = MMWHSDataset(\n",
    "        config.data_base_path,\n",
    "        state=\"train\",\n",
    "        load_func=load_data,\n",
    "        extract_slice_func=extract_2d_data,\n",
    "        modality=config.modality,\n",
    "        do_align_global=True,\n",
    "        do_resample=False, # Prior to cropping, resample image?\n",
    "        crop_3d_region=None, # Crop or pad the images to these dimensions\n",
    "        crop_around_3d_label_center=config.crop_around_3d_label_center,\n",
    "        pre_interpolation_factor=1., # When getting the data, resize the data by this factor\n",
    "        ensure_labeled_pairs=True, # Only use fully labelled images (segmentation label available)\n",
    "        use_2d_normal_to=config.use_2d_normal_to, # Use 2D slices cut normal to D,H,>W< dimensions\n",
    "        crop_around_2d_label_center=(128,128),\n",
    "\n",
    "        augment_angle_std=5,\n",
    "\n",
    "        device=config.device,\n",
    "        debug=config.debug\n",
    "    )\n",
    "\n",
    "    return training_dataset\n",
    "\n",
    "training_dataset = prepare_data(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(4, 4))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# # Use marching cubes to obtain the surface mesh of these ellipsoids\n",
    "# sp = 1.0\n",
    "# verts, faces, normals, values = measure.marching_cubes(first_class.cpu().numpy(), spacing=(sp,sp,sp), step_size=4)\n",
    "\n",
    "# mesh = Poly3DCollection(verts[faces])\n",
    "# mesh.set_edgecolor('k')\n",
    "# ax.add_collection3d(mesh)\n",
    "\n",
    "# ax.set_xlim(0, 128)\n",
    "# ax.set_ylim(0, 128)\n",
    "# ax.set_zlim(0, 128)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1007-mr\n"
     ]
    }
   ],
   "source": [
    "sample = training_dataset[1]\n",
    "label = torch.nn.functional.one_hot(sample['label'], len(training_dataset.label_tags))\n",
    "print(sample['id'])\n",
    "SPACING = (1,1,1)\n",
    "STEP_SIZE = 2\n",
    "\n",
    "heart_data = {}\n",
    "for class_idx, tag in enumerate(training_dataset.label_tags):\n",
    "    if class_idx == 0: continue\n",
    "\n",
    "    sub_label = label[:,:,:,class_idx]\n",
    "    verts, faces, normals, values = measure.marching_cubes(sub_label.cpu().numpy(), spacing=SPACING, step_size=STEP_SIZE)\n",
    "    data = dict(\n",
    "        verts=torch.as_tensor(verts.copy()),\n",
    "        faces=torch.as_tensor(faces.copy()),\n",
    "        normals=torch.as_tensor(normals.copy()), \n",
    "        values=torch.as_tensor(values.copy())\n",
    "    )\n",
    "    heart_data[tag] = data\n",
    "\n",
    "heart_data['sa_affine'] = sample['sa_affine']\n",
    "heart_data['hla_affine'] = sample['hla_affine']\n",
    "\n",
    "torch.save(heart_data, 'mmwhs_sample2_clouds.pth')\n",
    "nib.save(nib.Nifti1Image(sample['label'].int().numpy(), affine=sample['sa_affine'].numpy()), \"mmwhs_sample2_sa_label.nii.gz\")\n",
    "nib.save(nib.Nifti1Image(sample['hla_label_slc'].int().numpy(), affine=sample['hla_affine'].numpy()), \"mmwhs_sample2_hla_label_slc.nii.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View full heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data = torch.load('mmwhs_sample2_clouds.pth')\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.set_xlim(0, 128)\n",
    "ax.set_ylim(0, 128)\n",
    "ax.set_zlim(0, 128)\n",
    "\n",
    "for tag, tag_data in heart_data.items():\n",
    "    if 'affine' in tag: continue\n",
    "    verts = tag_data['verts']\n",
    "    ax.scatter(verts[:,0], verts[:,1], verts[:,2], s=1)\n",
    "\n",
    "def anim_func(frame):\n",
    "    angle = frame\n",
    "    ax.view_init(30, angle)\n",
    "\n",
    "plt.rcParams['animation.ffmpeg_path'] = \"/home/weihsbach/miniconda3/envs/binaries/bin/ffmpeg\"\n",
    "\n",
    "anim_created = FuncAnimation(fig, anim_func, frames=360, interval=25)\n",
    "display.display(display.HTML(anim_created.to_html5_video()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View sliced heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_from_plane(normal, support, point):\n",
    "    normal = normal / normal.dot(normal).sqrt() # Get unit vector\n",
    "    diff = point-support.to(dtype=normal.dtype)\n",
    "    dist = normal.dot(diff).abs()\n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data = torch.load('mmwhs_sample2_clouds.pth')\n",
    "\n",
    "SA_NORMAL = torch.tensor([0.,0.,1.])\n",
    "SUPPORT = torch.tensor([64.,64.,64.])\n",
    "\n",
    "# sa_to_hla = heart_data['sa_affine'].inverse() @ heart_data['hla_affine']\n",
    "# hla_normal = (sa_to_hla @ torch.tensor([0.,0.,1.,0.]).to(dtype=sa_to_hla.dtype))[:3].flip(0)\n",
    "# hla_support = (sa_to_hla @ torch.tensor([64.,64.,64.,1.]).to(dtype=sa_to_hla.dtype))[:3].flip(0)\n",
    "hla_to_sa = heart_data['sa_affine'].inverse() @ heart_data['hla_affine']\n",
    "sa_to_hla = hla_to_sa.inverse()\n",
    "\n",
    "hla_normal = (hla_to_sa @ torch.tensor([0.,0.,1.,0.]).to(dtype=sa_to_hla.dtype))[:3]\n",
    "hla_support = (hla_to_sa @ torch.tensor([64.,64.,64.,1.]).to(dtype=sa_to_hla.dtype))[:3]\n",
    "hla_support = hla_support\n",
    "print(hla_normal)\n",
    "print(hla_support)\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.set_xlim(0, 128)\n",
    "ax.set_ylim(0, 128)\n",
    "ax.set_zlim(0, 128)\n",
    "s=1\n",
    "\n",
    "for tag, tag_data in heart_data.items():\n",
    "    if 'affine' in tag: continue\n",
    "    verts = tag_data['verts']\n",
    "    selected_verts = []\n",
    "    for normal, support in [(SA_NORMAL, SUPPORT), (hla_normal, hla_support)]:\n",
    "        selected_verts.extend([v for v in verts if get_distance_from_plane(normal, support, v) < 1.])\n",
    "    if len(selected_verts) > 0:\n",
    "        selected_verts = torch.stack(selected_verts)\n",
    "        ax.scatter(selected_verts[:,0], selected_verts[:,1], selected_verts[:,2], s=s, label=tag)\n",
    "    else:\n",
    "        ax.scatter([],[],[],s=s,label=tag)\n",
    "\n",
    "def anim_func(frame):\n",
    "    angle = frame * 2\n",
    "    ax.view_init(0., angle)\n",
    "    \n",
    "plt.legend()\n",
    "plt.rcParams['animation.ffmpeg_path'] = \"/home/weihsbach/miniconda3/envs/binaries/bin/ffmpeg\"\n",
    "\n",
    "anim_created = FuncAnimation(fig, anim_func, frames=180, interval=50)\n",
    "display.display(display.HTML(anim_created.to_html5_video()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shaperformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapeformer_data = np.load(\"/share/data_supergrover1/weihsbach/shared_data/tmp/ShapeFormer/out.npy\")\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "SPACING = (1,1,1)\n",
    "STEP_SIZE = 2\n",
    "\n",
    "verts = shapeformer_data\n",
    "ax.scatter(verts[:,0], verts[:,1], verts[:,2], s=1)\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def anim_func(frame):\n",
    "    angle = frame\n",
    "    ax.view_init(30, angle)\n",
    "\n",
    "plt.rcParams['animation.ffmpeg_path'] = \"/home/weihsbach/miniconda3/envs/binaries/bin/ffmpeg\"\n",
    "\n",
    "anim_created = FuncAnimation(fig, anim_func, frames=360, interval=25)\n",
    "display.display(display.HTML(anim_created.to_html5_video()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare against mean shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MMWHS train images and labels... (['mr', 'ct'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 images, 30 labels: 100%|██████████| 60/60 [00:58<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postprocessing 3D volumes\n",
      "Removed 0 3D images in postprocessing\n",
      "Equal image and label numbers: True (30)\n",
      "Data import finished.\n",
      "Dataloader will yield 3D samples\n",
      "Loading MMWHS test images and labels... (['mr', 'ct'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 images, 10 labels: 100%|██████████| 20/20 [00:22<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postprocessing 3D volumes\n",
      "Removed 0 3D images in postprocessing\n",
      "Equal image and label numbers: True (10)\n",
      "Data import finished.\n",
      "Dataloader will yield 3D samples\n"
     ]
    }
   ],
   "source": [
    "os.environ['MMWHS_CACHE_PATH'] = str(Path('.', '.cache'))\n",
    "PROJECT_NAME = \"slice_inflate\"\n",
    "\n",
    "from pathlib import Path\n",
    "from slice_inflate.utils.common_utils import DotDict, get_script_dir, in_notebook\n",
    "from slice_inflate.datasets.mmwhs_dataset import MMWHSDataset, load_data, extract_2d_data\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import SimpleITK as sitk # https://simpleitk.org/\n",
    "import numpy as np\n",
    "\n",
    "THIS_SCRIPT_DIR = get_script_dir()\n",
    "\n",
    "config_dict = DotDict(dict(\n",
    "    state='train',\n",
    "    dataset='mmwhs',\n",
    "    modality='all',\n",
    "    use_2d_normal_to=None,\n",
    "    data_base_path=str(Path(THIS_SCRIPT_DIR, \"data/MMWHS\")),\n",
    "    crop_3d_region=None, #((0,128), (0,128), (0,128)), # dimension range in which 3D samples are cropped\n",
    "    crop_2d_slices_gt_num_threshold=0,   # Drop 2D slices if less than threshold pixels are positive\n",
    "    crop_around_3d_label_center=(128,128,128), #(128,128,128),\n",
    "    crop_around_2d_label_center=(128,128),\n",
    "    align_fov_mm=(300.,300.,300.),\n",
    "    align_fov_vox=(196,196,196),\n",
    "    max_load_3d_num=None,\n",
    "    device='cuda',\n",
    "    debug=False,\n",
    "))\n",
    "\n",
    "def prepare_data(config):\n",
    "    training_dataset = MMWHSDataset(\n",
    "        config.data_base_path,\n",
    "        state=config.state,\n",
    "        load_func=load_data,\n",
    "        extract_slice_func=extract_2d_data,\n",
    "        modality=config.modality,\n",
    "        do_align_global=True,\n",
    "        do_resample=False, # Prior to cropping, resample image?\n",
    "        crop_3d_region=None, # Crop or pad the images to these dimensions\n",
    "        align_fov_mm=config.align_fov_mm,\n",
    "        align_fov_vox=config.align_fov_vox,\n",
    "        crop_around_3d_label_center=config.crop_around_3d_label_center,\n",
    "        pre_interpolation_factor=1., # When getting the data, resize the data by this factor\n",
    "        ensure_labeled_pairs=True, # Only use fully labelled images (segmentation label available)\n",
    "        use_2d_normal_to=config.use_2d_normal_to, # Use 2D slices cut normal to D,H,>W< dimensions\n",
    "        crop_around_2d_label_center=config.crop_around_2d_label_center,\n",
    "        max_load_3d_num=config.max_load_3d_num,\n",
    "\n",
    "        augment_angle_std=5,\n",
    "\n",
    "        device=config.device,\n",
    "        debug=config.debug\n",
    "    )\n",
    "\n",
    "    return training_dataset\n",
    "training_dataset, test_dataset = None, None\n",
    "\n",
    "if training_dataset is None:\n",
    "    train_config = DotDict(config_dict.copy())\n",
    "    training_dataset = prepare_data(train_config)\n",
    "\n",
    "if test_dataset is None:\n",
    "    test_config = DotDict(config_dict.copy())\n",
    "    test_config['state'] = 'test'\n",
    "    test_dataset = prepare_data(test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ids: ['1004-ct', '1004-mr', '1007-ct', '1007-mr', '1008-ct', '1008-mr', '1009-ct', '1009-mr', '1010-ct', '1010-mr', '1011-ct', '1011-mr', '1012-ct', '1012-mr', '1013-ct', '1013-mr', '1014-ct', '1014-mr', '1015-ct', '1015-mr', '1016-ct', '1016-mr', '1017-ct', '1017-mr', '1018-ct', '1018-mr', '1019-ct', '1019-mr', '1020-ct', '1020-mr']\n",
      "testing ids: ['1001-ct', '1001-mr', '1002-ct', '1002-mr', '1003-ct', '1003-mr', '1005-ct', '1005-mr', '1006-ct', '1006-mr']\n"
     ]
    }
   ],
   "source": [
    "print(\"training ids:\", [smp['id'] for smp in training_dataset])\n",
    "print(\"testing ids:\", [smp['id'] for smp in test_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset.eval()\n",
    "train_samples = []\n",
    "for sample in training_dataset:\n",
    "    train_samples.append(sample['label'])\n",
    "\n",
    "train_samples = torch.stack(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 128, 128, 128])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjUUlEQVR4nO2d244jSX7efxGRR5J17K7pw85odrUja22tIECQLMAXvjBgG3oAP5ifw09gGRBs3wk2BBka7exJo92Z3Zk+VNeJVWSSmRHhi4jIA4vVXT27s8vsjg/oLjKZTCbJj1/+zyGstZaIiJFB/r5PICLimyASN2KUiMSNGCUicSNGiUjciFEiEjdilIjEjRglInEjRolI3IhRIrnvjv9R/pdv8zwiIgD4H+a/3Wu/qLgRo0QkbsQoEYkbMUpE4kaMEpG4EaNEJG7EKBGJGzFKROJGjBKRuBGjRCRuxCgRiRsxSkTiRowSkbgRo0QkbsQoEYkbMUpE4kaMEpG4EaNEJG7EKBGJGzFKROJGjBKRuBGjRCRuxCgRiRsxSkTijhVCuH/vKe49ECTid4S3JeO2/d+D1REicXcB77FyflNEUyFilIiK+/vCt6my4djvsMkQifv7wO/KNOi/zjtG4kjc3yV+n7bsO6bCkbjfNnbJ8XpHSAuRuN8e3pKwQims1u1tAMLfO2DX6292Tu8AgWNUIWKUiIr7LUH01PKWksJWNRVKIZIE/P4oBVqzudyyEOLWtrc7ufE7bZG4vw0IMSCAyHO/2RFEJLc/5m1kFFnmSL5BcBG29Qgt6Aj81ibDO4BI3N8QA1K+wSbtQ+Y5pLc/fpH2FBfA2O64/q9dr9vbQoj2h2JWq7c8e0Zr90bivi16l9n+pb9P4L6aiiwD6Z+jlLu/Dda2yt0+WyqEkti6dveDyeGPYcM2fx5yMgGtMauVU+93WIkjcd8G2yIFQQWtbU0DWRZuu/SqmNxDiYNtKwSiLN02rSFL3Y+iaSBsbxrsYukiEdtO864fxzuEGFWIGCWi4t4HG0rbj7O2Dth00u0QlFZJp6R9qJ5WbNqXSoI2kKXuvlEgpdsvPAaQJIjpBLtcIthQc6VgvXZXgKC8WreRjXu9xxHYu5G4b4k2ZBWgFKLIW3vU7dQjQZZigxPmTQabDC90NlWIWiOq2u3TeJIZT1QlEdp0x22cXStmM+xyCXXTHSxNnINX9Rw1IUCp+9u8G1GSXUQk7l3YYs+qvT3MYoHY23MbjO4IKwSUhd9uMPsThHZffiCqlRISiUklJlOIxnQvlylklmBSiaz99sYgF46AFmjPKJOO1NY6ezhzRH8dMd81Ry0StwdZOOJtCyupvT2QAjmbtspqoSNtnmFzd4m3WYJNneOki6QjrhJgwWQSk4qW2MKArA0mc/d14b4WVTWYMkHdrBHrBhucPGMRdePIq2RrfgilnONW14MUMkoh8/ztwmU7rrrROYsYJaLi0lPaqmpvy0nnbAmlBrHYYEYM1LbMMVOXCLCJpN7PEI3FJoJm4vRBZxKTgGxwf2unaCYVyEaBteSXGutfyyapO4YUCJMhjNtfLtZgjDMdvMnQnazPwNGZFiEbF+K8Ic48ZvMhErcHWRTdF4zPYoFzhFLv6SdJ62QhJdZfpvVBiUnd9maasN5XWAn1RCD8FVvn/mnelxKpJ6gCWYNJBPVEIryJm127G9mlf563fe0sRwkBjXGOmnfiRN9JkwqkT1j4yEMgsPAmxO4aAm/Ge0/coLCbEEp1qVYf3mpJK72FpTWUOSZLaKYp1bH7OOuJROeg846YAGpl0blo7wdCq5VFZ47QthfdqhJJsrJYmZBUnSNH5l5f1gaxqrtz1sZ9o9a6pIdy781WlT/ft/xwdhjvNXFvkTbk//umAT2TwMdXQ3jLHM+oD3LW+wkmgfWeI5RJHGlNBjoD6z/lphSYfNuZCOTKO2kNKM8zWVtqJbASdK7oP9UqZ0aoVCKXTmltnkKjEevavZfgtLXPqsB0KeU3Omw77KC918S9E1IMUrbBjsUYbJ5hc/exNbOMek9RTx01gimgc4HOwWRDBbUbuYKmcKRIKkEztaiVJ6nPGwgjSK/dD0GtwHhFV7VFrSyysZhM4o0YZwKkyqWJb5Yd6fIMVuvuvXnltdYOow/bsKNFODGqEDFKvLeKe6dtGxwyqbrimNxXY6UJtkhZP/ARB+HsWdlAdSRam7bec+pqEu+9+8NYCTaxiEa0twHq1G3TpbNj07m/xGtY74NaO7tYrYLqiVaFKQTQFdWomzVgsdMScb3ovTGBKAoX4zWdelqt36y6O4j3lrh93KqmUgoxLQeXR5sm2ElOs1+0RqMuJGplWT6QNBNB4/ncTHyYK7t9ebUKrLJYaRHGHcikFqHASrf/+tAT+Eq0tRAmoY02CANYgRWCpDIYH53QZYJVkuSqQjQGO/PRkeuFs8/XNe8K3gviyqIYxGjv3tHHZ2dTWK2xhy61K1Y1SImeZlglMKl3wlJBU4qWtDrviNonrZ70IgIBSa/uVnd2J7ojcFMKZGORtVPoeuajFNKprxHQIEGEDJzPvE0z5LJpw15kqYs4KNN1WeDCZNZ3VoTCobEo73tBXLjbNOh3LYiiaJ0Ruz9rt5uZ297MUqwU6MKbBBNJPXGX8XraI+qeaYOkVtm+W+9fyN66bzML0oIRiKX/YZQGcS1ZHVvSG0fe3pMceVPwmWOEdjuoJaAENlSOlRniunIFP/OuewLTMFa8k8Ttk1RMJ11htoddLt1jZekKtIuQGZCwrjEHU6dEPaxPSuqpQliL9pfmxsdklycWk3vyAdg7CAuOtJsuscSRFvfX7nlCrSXNkUEuFU3ZVURaFZIajryN/yG52xI5S5FrRXJTt/ubWYG8rpzd7n8Btm4QSdJ1UsBo7N0YVYgYJd5JxR0UdW97vK/Avs4AQCxXmAf73WPKO0aZop4qZ8/m3W9dF84Otcpi074jZ8B6ud1UWPmGeGjvcZEbrBbYxOKTuu60sNQzp/ZWOjsYoCkkSWXQuXQ1Dv78RROiGxLRc9LEpMRe+HxyuMLcpbY7lox4p4gri2JA2k0TYdB9ANgiBykwhYsqSCmxUmJzhUkk0tfL6jLBpP6ynA+v/00JJjcgwCahQ8FC4/8aMSRr/7bZsCWkHfDDWhDKYnMDSGyoeXBuFSYRSAW+3AadW4R1k8plbTFr936TZd1l/vqRBV+QEzomIDpnvzNs2rP3gS265KnNuo/AlCm69B44UO87Qq8OfMFMKQfZr8Y7ZkILTKkhENcIyIz7m5gBQfvEFCqQRbSkDft0b9AiywZDgjE+vitdVk00YNddzYOVYIXASosuBKrqCtiF9sU4SgHe9m3u0dKzoxg9cbeR9ZbSArbMsZNhoYApXbJUrIZfnjCWZpayOnAs1bmgKVzoK1naDe/eO2JJL+TVc7QGf/uv0SOnUF1EAUD4Y9lNRe69npUCXVqQgnTutqsVmBRAIIzsyiNzhZx7h68/cKTRru2oblo/0tynP20HMFri3pn5uoO0d8FKgS3dx2CVRJeKei/BKtHaiEa5WK2V+IKXLp7qyAM0ckje1+BWV1CP4KJv4/ZvpwbbeGJr//rCZed05u4n0tVLqLX7cRlfRcbCRyKajek5icI2uPLHkE3rT8wZfFC7Y99CjCpEjBSjVNw3ZsB6CGpry2Fa15QpukjQhUKuQy7V/zH4CIJo7ycLy3rfqa7x5VjOpvQH1IJWBzaU9y6FFW+KMGwi7K/deQjtUsGhbNJkLr5rlDN3uhoJgc1TxKrBZili6Rswm9vKKvN8FObCKIkbsGnf3ko0lDm27DUxqo5BgbS6EDTeVMiuGlYHyhd0i7Y2IEA20ExdgQu4skWpwdSiLZjZim027tuSFlyUArDGumId3dU6+KMitKWZgJzTZu/kWiNqT0Qpb0VXSDN4UyPljoXDRmcq3EdtHWE70jZT9y+gmaQ0ExcpaIruI7h5koIQbdFKQCBqem2RvWiSSe/4Ihvv/X9La+i1Nm4IvWZdDa97PNxw/3Thuo6BrtZ4c0CfFIPi+VvYIdLCSBT3PmQNatt3xAJpA0Lbd3BaFie+INybBOsDd6nNrizC9qIHwpkH2dyyll3NgDACnblUr1zKNuVrC+0iBGrDGfomKgvYRrqQ2R1QvkbcNWC627Khayrb+AXZTcUdIUZB3G0IZsKmeWAOp+3tPmkBmkkIb0kX4iqdXdhHPXNRA2G6JkfZuGC/6dL8A1hlGUxCaoSr/tICkZp7EfauCUi26b1gE4zw4XNlHUwGYNl1EYf9rBKItQ+HSclrm8+8IsskcW09O6a0AeP/6UW8lxit4gaESi+OD9ttm0oLTm21rzPQuYsYqBWAbVW3njoPfX1oEaazFYtTl0KtZ4JkYWlKXx1WWGTjbE471W0mjFq2yQSrxZ2Ke5f9u9nm1ZoJGwkJsSGcauUiCCaxpAvaBAS4KIqqhoXkIs+woRct9UZyvW6L13cZO0/cbfbt1nqE5YrVJ4+2HkMXqjUPAFb7jrTLDwTrQ4suuvCBmWloBOlFd+1f70F6I1DVkIA2tdAIkiuJrgU87Hnm0mJXvji7RzipLEYLpLqf+WCldaG2RrQdE+2xtDNdxEZZraxpxzsBgxllGNOmtAcwYdCem4BuQ5RhR5sld564m7irHmFQ1dVDM1GsDhWrfcH6wDthhxZdWGxmsIVGXnmn7bAmn66ZlivMU8n1jfvRNM8L1oeCvV+454eBHulcYhJLshA0U9ObHCPc7cTcUlUTQlgbztY2Ipue0opGtqap0ALR3FbF4Ji59iDBrZEfYVqk76sTi2X/BMIn5v7clUHbEYyCuHeRVZQlduoUN9QdBAcs4OaRe4vXH0P4InVhOfzkjL3cXSarxu3zB/vnXK0LCtXw5dUBh/uu2fDVWmGvEhZPJWohyC/csUMKGANqIdt4MNKiMo1eK2Rq0JWf15DenRLeJHKAXSkw7tSD4grj/rkWntvPy66DqePer6oa1yaxdmNM+xNvhJJYbaAejmMKq//saiJiFMS1N4utyQY7LbFFPz47JK3OJesDwfyPfHX/gftyPvrgnB8efU0iNb9aHLb7f5Bf87S8ZCLX/PDgKx6lVwD818v/gC4N69JQfJmy9uKeLEE2guqBz1K1KiigF+yQuXt9lbi/zXr7x7415KXFa2clhUEi4KIKbpSTC5HJjdoEczABbVGLangQo2+38+wwaSFGFSJGip1W3OCY3VLb2XRQUwsuG7aJy+8plh+4VvCHH13w8cEZAHvpiqf+ep9ONU/8VLmn6TlXpuRxcsGZnlH5ooRPnrzgq6t95i9nrI8NaumU0TlskM5dXa5snGrVh5pm7s8n7exco9XAMdPrN+hGL4Yrl93ttk29jTO7v2plSRb4SIdtTQVdJM5cAORi1X527TIAeYa9vLr18kIpbLObDZU7Tdy70Cet8CEe7VO3q0PF1cc+7FVamkNNeli1pAX4o8kLAB6mcx6mc/Zl56T8Sf4rXukZT5NzMs+MPz96wJfnf8rkeMFCloSPbfEEZl84AtfTriVdXSv0TIO06KsUitCI6OctePKqbLvNqxf+a9HCOWLrjTBYmLDv7dvglJlEILVBGFfaGNro5cqt5iMXzlQaTHUMx5z5rmatXUPo+cXWc9sVjJK4d0HnktWBL7DG1aamhxVFUSOF5SDtbLuH6ZypXPHd9OXgGArLd9MzznSn8t8tTvmzx1/x+eUD1quUxtuy5dfO3i1fuuEeyito9cB25BVACIt54or8DbZjsHWVn72QgWiGRT/pVeeotcU0tavNtQKwgmLRex1rsYlEbKkIG6A/BGWHbdzREFfMXCp300QYOGel61IIgzn0ozWzomavcDHJR7m7HH6cnwLwneQccGQNeKSWzG3CsVrwo9UTADLR8BcHvySRmn9Yp8xv3Gvq0s0wqKc+xutrHLPL8ONRmNJgS0+AWjoyasFd8QWrBcIrtK2lK6jRflxTE9rQffzWdGYCuPR1dm3cxMfaOqWFdlCIWKxcDNe8vuDdaoOcTdFnuzv4eeeJ+6Y+shAG07mkOpIuRlsOv5i9bEUiDMfJTbvtB9nXFEKTCkPaI27aC38+Tpzte2UKjtU1AM8X+2gdhjlL5N/tYTI31Sa7Cs1kAisFaQONlhhPOJu6ZILVwr3EhgKHqIIN4TNvJoSYbeItGhlMhAbkuptsLhvaMFg6H6qlXNbbEw9BYQfLsO6u0gbEqELEKLHzintfOBPBD4zbd9fP2eGCvWLFcb7gD6enPE2dabCnlhSbif4tOFYuAZGKhp+tHzORK/7dw8/5m/oHALy8mHHzoaF8Jkmvu+cJDfkFNBNfx1D5bFli3dzc3LhqsqCwiXERhEYgK9kqrFq7Ott0PnTClM/GygaSZXe1SKpO8dWy6ZadAjdyf3Nldr8vjW6V1/ZUWe3toa9uRxt2ATtN3DeZCbZI2xrbpnB1B31UVcqTvTnH2YIPs15UIX3V3r5lJgDHsuHMJK3teyhX/CD7mivjwnP/6cmPAfgbfsDX64SlyMh+LNqWHqFd4Y5aBeKFExbU+2CXYTETt1m96qrARSMGNbVC40eM3n7/ycIiNCR+/GgYhpdUBl0mSJ8NC9EEoM2etQiEDqjXt8m9g9hZ4g7mJWyJ24Kzb0O2bHXkJspw2FVAHe8vEMJykjnmBJu1tnJg26ZbElabyzsfq4orU3CSzJF+aN2fPfgKgK/0EcvHeUvQ4tTC0vWo5Rddj5qsIXnu14HoGWmba0K0i5toP5UxGbYdqZUjrGwcaUMhfFIZ1Nqiln7uja/BNVkCkwwmOfJ6OSRuWDOtX7cAUDcxqvCbIEQTNhHU9vqpewurY1c4A5AVjrxKGj7ZO+VR6gib+jKqC5PzVC22EjbgWHZf2twKJsLyp9k5P6m77YfJgo/3zqnqhDNgfeEYKtdubm56450vb0boHD9AxHVZhJYgKx0Jde7KJjeRrroh0QCZP65J3L+guKq2raOmqqYdduJa0w1iWzQhbPPDq6mqnU/3wg4S9z5tOmaSY8qEZqpYHbU1We7/lSJcGD/+jrNppbA8Ti7a558opy613a62AanPLD2VigvToIETdcOJuvGPux/CYbbkR/ljvipdEcPlLKf8RQoSpr/uum3zlqx2EJO10tmqVol2HbTBZ1Jb1wcX7FAl2u06F9RlsKHdmr9uPkRnfqRXDWq1hYhBbUeIGFWIGCV2TnE3Ya9vBuaC2RijpHsCbYrhvILjbEHSu+QHu/V1tq3bz6ltKqTfT3EoYW4ajqXmzDgJ/X76igcH1/zd4hM+KV/wD3sfAvDT8w+4PCxpPp9RPRCtY6XWbrUc65eACsrqZjWI1nYNa5ppv+ZvKIDvB0KEtqwO3GJ+YVK5XINsJGptELoraxTaYHOFWIbFrX1iIqitteCjCWI2w173QiQ7ip0nLtzOlpkyQZcJTSHbNcF0AbIS2IOGLHdfyKfnT/jrJ//UFs18oJz3dGYyHqm7s0LBRFC9rsRUKI6V4kyvWvs3EPivJj/nle4mmP9Bec61zvlf2Sdc/uqA2eduv+pIUr5yBJG1bbsLurJE4YdF97oOrO2tTOk7OA4k630wuStrDCgXrmPZJJJkaSnOfW1CL3MGG7UKPdKOCTtPXDGbbi1HVcuG6ntZq7iqEtQHrgth4lO8h7mzZc88qV4Zp9yP1fbYZD8IFNR2E8cq50y74x9LzbFc8LlfteST/Jk7TmG40FP4EP7W/hHVA1/kflpS/1qRXjvnLNi+TSl6K+rQTtoPMx90LqgewOpRt1BE8mBJmmqW8wL13NmzydKl/eTC/Qj6q+uAm+Yjrxa9cZFiK2nFbIaNRTbfDCGGG9RWH/n7G0MrguJuxnABjvJuuaT0HgkHt1+ntqnYHs88Vu6cAoEPvez1VfdQ3fCXs3+h+Y7iFzfHAHxRHHI9m7C8Tih/rdpVJl2sNjRsWvIzX+l27KY46llDerCiTN17yBLN949PaYyieSD5LHkMQFUXgIsDy9q0Me5k4aIsZuKJ25+Ra61b6rWPHS1l7GNniQu+y8Hf3iSsLhPUqgvMq8otKpLmDR/tu/DXD6bPBs+50EPF3aRlIG3hCVv7ScpvIvCxgrlZ8pPwOsb9yA7VDX999P/4SfnUPfAQ/vb0j/l6vsf6Own1yidP1glSWZK0IRWweOgU9PD4hkm+Zpau2cu6yrbGKCaJMwO+Pznlp89OAFg/0Mh1QrKA7JqB4orGIOcVVG8YtTQSxKhCxCix04oLt6MIfcy+WmOlnxp+6D112dlsp/WMP5n8GoC6N0r8lZ62zpnmtvJq7GtNhW04kiV/nDqb+ue1be1poE2AAPznkx/BCTyv9/lieTQ4xtW6HERBJska1Vta6s/3vgDgrJnyKL3kUC34dPkhx76p88WrEmGh3hOki+4K1baq31XO2DSdudAzE8zNzfb9dwA7S9wwL0G9vECfHA4e076btpkoUl9kkl0J1kewuCqYHziyX9QTzprO7gx27k90SSY0x2rB8Ua0/y6n7D44ku6c/zIHWPB/Vo7Ah6ojwFkz4zi55jjZEnIqz7moJxymQ9v8OLnhOLlG+Sre4+SaE3XFT1ZPMVZQ+zJLm7mFS/IzV3S+OnJOYXK52p4166NP2HkMh701TOVsObFcDtrPw9L29fH2zJqqLMULyXqV8fLIqV0qNTdNxh9OT7moJ23NQsCZnnCm6WXCDI/UMAx2HyS3NNvhk7TiEyp+XrtzfmWm7Kllq/7/unS1Ds/rg8HzQt1wn9zP6wP+uHD7p2i+m15Q2ZS/n/9B22Z/UTaYtPtKk1CzYIwrIp/fX0F3WW1hB4nbh52Wramg/VgludKYXN1qRU+WsPJX3usLX1W2f8VxtuCivl1l9uPVE56m59Q24ePEOWu1J+zbmAivQ1DgT7wJ8QkVP5c3/HjtOiuCEh+qG142Ll18nFy3ResAD/ztk3JYBPNSlzxrDnmYXfPP9iEA9ixrndUm78alrh9OKP7pjPtgDGoLO0jctrN3NkVvkPZNSJawPug6CL662uc4X3CcuUvvy7Vbm/eH01+5x+sjTpJ5R1hv274N7lLbPgKBwZkRx+pfAPhZ/QCAB/KGB9kNx6q69dxH7UhQyXMfc32pS/6x+ogfL59wtp4wrzo/YH1oyC7UIMuWvbyBSW/Qw2YlGOMhbECMKkSMEjunuAF2UiAr7/m/RnGDHQeSpoSkEhi/vtf1xYT/W33EX3z05eA5/3v9r/j3Rz9t77/UTo1O1JKXuuFpcj9T4T5quw3HXi7+KncF7WcbftOjOwYvh/N81hzy6c2H7fblqvt88lNF8cqSLgz5qztitn31hVsKvOv2LewYcWVRIPbc5ZzTC3h4eO/nOgIr5MrVLAA0lYKi5pfzIz7eOx/s/+nNh5xkc+cY9b7Hp2rBSz38wk/U3SG5N+GFXtzalm5Mwjt+w3XvuTYcS6j9KiVf1Uccps52f7HcY71wIUFhBPju33RhUNfufcjr2yZIi8VydGYC7BhxNyH8jCs1zdv0JTgHTamNTFou0UXoBPBt4r9MqA/d45+dPmrb1PfzikTqNmb6k8o5S6/SGSr/komsedbs8W8yR/aXesWZSW6Fzp6ou1uLthEWusKcR+ru8NRBzyY+1Td81ezx36uP2m3Pa+fI/ezqhM+fP0ScO8XNLiX7//yW40AnJfSIOwa1hR0jrqkqVFBcwC4qxLRE3nQK2CdwH64vywIC/JWvKUH+dAr/1n0xwYmZVznHH3Rf0IvavebDdM4rM2UiLwA48y0Kzxp/Tsl8QOiv9QIFfKAmA6J+8BpCH0t9S3Hvwv9cSp41H7YRh0BYgLPahfzM8y486OvjKc8a1NK8XmkDFkvk3mx0qrtTxL0PwgwsPUlQy851tlIwfWaojmTb7dp4BX6RP0J9r/tiyrzmn04fs5evOcyXbTHOz5aPOG+mXGRTTtRVR1iPcP9H62HG63EyBxJOvCK/0Atemu6jDdvfpLafrjdf74CXzT7P6/2WqAGnqymfP3/oPxP3PvNz1yiplqYtrHktvG07NtJCjCpEjBQ7pbiyKLBzl90Se3sInzUTyxVMhw5SX20BmtL9Botz067REFC+EKzqGetHPvsWBjAPE1acryawB5dNycP0gB8Ww2jEXQhK/Oyux/3fx8mcH62e8DK5HDz+j95+3VTW05W7/TAf2p2nqymfvXyE+GVJthRMnrkrTHFumH25HLaj3xNjsW0Ddoq4fdj5vCUugDrtir/1w9tj85OloSml/+suye2AjHMAgVo6J2Z9mKAPGy6Ysshz5oXzyqWgK3KZwac4Qt2XwG9CS/DG/WI+XX54a5/T1ZTLVfe+D/Ilp6spD/OblshfXB2x+vEB2YVg+pVtW32KV01L2vvYt8FEGBtpYceIa6pq0OVrb7r44i0Snxygi4Rmejs3H6a7BOVNKgvnoMou6tBcufb26nFNdeXUXBWdih9lyzbT9tnNE06yOQ/Tax6ll5zc0UGxiZd6+AP7bPmUs3p6i4jAgKx9hO2Xq5KffuEWZ0mfZailaG3a4pW7kgS79k3hr3cBO0Vc6IpsWrNBKcRk0pI4EFi9vEROS6Dz4Pskhi0E9vfVCuTaFZ5nF137T/VYE6K9/8B3tp5ff84uOIIH9It4Xm44WgCXdfej/PuXH/Lh3gUA83W3/XI1LCK6WWVUy4zmMmP6i+795eeWvV8PCXsnXkPWMaot7CBxAwKBwXmQYuJbd3oEFjdL+jm1YAoEa1iHBU2mCfV0ww89d82L0BFbVQpduB/GDaWbQwbwuAvHnV9OyQt3OZ7kNb/Ekfl8NeE871QzEPrz+YM2ahEIGsjZv3+zGq7uDrSEPfgsQVW2/eGVZ46w5ZdzzCQjeeGuAGZWOLV9g6qO2UQIiFGFiFFiZxW3D3NzM/iF9U0HeravXG5cMkPjY9WQv+pWnGwmiqaUFOdOUSt/dFca2ZvR5eOj/KJAFxZTWGyhWVTuNVfeqTt97m1ZP5F84pMbk7xmv6hctAK4WWetsk7zNV9duedVS7etucyQlSQ7d8fJV7B/fltp81er1gkLagsgXwzT2tswxpjtNoyCuDC8rPVNB/Hqwm0s8rbovN1vsW67Z23eGRWJHzGvvDee+KIc1w7uO2yPREdcj+xCAioMHm9hj4YJheoLZ99WwGmxPdmw6BE0wdnd0yV+9UpH1GTphoOkC9MOsgvvC3pO2D0drk3Syul0tObCaIjbh7m5gZsb5LQ3c2F+jax8m06v+ilwzADpqmvTVlXTrtQTSKGWhmQpQYBaJTT+MLoQcLk9Tbs6pCVgQFiDwkG2P4CwWo8uLdmFaCeMby61Gq4E6aJ3Xov6rQl7l7qOlax9jJK4AcaTt70fvqhNZXl0gryuMDPnDMnFGjPJyE5vMJNssNSUqhxJ1NKgy46Q9cQvTHLUFfMA7SqTA1z0zY3+A/aO2w7JsjMHYAth3yNT4E0YNXFhw4SYbh9Jap67lXXkomuclJMSMytIXlwhA6GvK5oPuthr//IciBxUEByZw7SZvm3cPqe6u1Ir6YllMAfC6/TDW60Ne4e6vg1R3wWlDYhRhYhRYvSK20dQlDuV16uT3Js5BXv+EvZmyKBmk7K9LGe9fL+Z+Nlci+FY+tI/1kxSZr9mYFpAZ17MvnTH31z98q7EwTaV/U1NgHdJbeEdI27A5pe0SeQ+Cfq3JTgST8oBaWS4782LfkpVXletqdEec5IhF+u2sSLsHz7scIzW5g6268brbp7f2+JdI2sf7yRxN7GNyNvUuXn2vN0m9zp7uG1vmV8P7OT2eBtkC7pr5teD47SKv/CF28/99rDDe+JY/TbwXhB3E30ib0Ym+o9vOn4t2fduk3fw/DsU/XXbfpvY9p7eNUTnLGKUeC8VdxPbbMHNbdtUuI83qfDvGu+yfQuRuN8Iu0qKXT2vbwPRVPgt4X0izS4gKu7I8b7+YCJxf4t4WxIN6izeUwJ+U0RTIWKUiIr7e0RU2W+OqLgRo0QkbsQoEYkbMUpE4kaMEpG4EaNEJG7EKBGJGzFKROJGjBKRuBGjRCRuxCgRiRsxSkTiRowSkbgRo0QkbsQoEYkbMUpE4kaMEpG4EaNEJG7EKBGJGzFKROJGjBKRuBGjRCRuxCgRiRsxSkTiRowSkbgRo4Sw1t69plFExI4iKm7EKBGJGzFKROJGjBKRuBGjRCRuxCgRiRsxSkTiRowSkbgRo0QkbsQo8f8B3rNMOE6ZYf0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_samples.shape)\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.axis('off')\n",
    "plt.imshow(train_samples.sum(0)[:,:,64], interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques, counts = train_samples.unique(return_counts=True, dim=0)\n",
    "if uniques.numel() > 1:\n",
    "    pass\n",
    "sorted_idxs = counts.argsort()\n",
    "resulting_label = uniques[sorted_idxs][0]\n",
    "# print(resulting_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 128, 6])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bincount(tens, length, dim=-1):\n",
    "  \"\"\"Count the number of ocurrences of each value along an axis.\"\"\"\n",
    "  mask = (tens[...].unsqueeze(-1) == torch.arange(length)) # Last dimension will be broadcasted\n",
    "  return mask.count_nonzero(dim=dim-1 if dim < 0 else dim)\n",
    "\n",
    "bncount_along_samples = bincount(train_samples, train_samples.max()+1, dim=0)\n",
    "bncount_along_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEjklEQVR4nO3dQU7bUBCH8QFyhi5YcAYkRCW2VBUn6K67coKeoWtOADt2PQGqYIuEhBSpN2DBKUjdRWVhpXb87Dzn+T/z/ZZNGozyZTp2oNmrqqoyQMx+6QMAxiBcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSFqk3vHz/pcpjwMwM7Nff34m3Y+JC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEC0mEW8Db+UnpQ5CX/JGoGKcr0uafLx6e7e38xBYPz5337botKiYuJO1VVVWl3JEPoR5mynXA8/TlQ6gLmnqHZUdmx81m1zFF33sJd0t9wb5crgY/5tH1QfLXjhov4W5hU7Rjgm37u30RR42XHReSmLgDpeyy20zbTY+VukJEQLiZ5Ix1qPU3MyJgVRDycrnqfYFEuVRGuAO0RZESU24lp/tcEG6iuU2yTfHO7VinQLiQRLgJ5jrBIq8MhCuuK965vthy4XLYBlO8nYs8CHcEgi2PVcGBEpfkSiNcSCJcx97OT9yepBEuJBFuB6+TygvCDcDji5BwIYlwIYlwW5wuV3Z29dR5+9H1gdxvI3hbFwh3zeny34X8x+8fCx9JPh5/K4JwG+pozczOrp7s/vbG7m9vOu+vMnW9TVuzwD+r0Iy09uPD78GPc3R9IPF2q7epGyrcXLHOjcrkz4lVAZLCTNzT5Wr0dK333E9fv7XePvd1wduaYBYk3LvX5daP0RVtbe7xeuN+VcgRrZn1XmEwK3N9N+J+axYg3BJ2FVPf11k8PLtcE8wId7C+qVtTfHdNCeFCkuuTs1z77bq+qwxNOU/amODvXIc7tfvbm+R4aykRE2g/wt1Sarw1oszD5Y5797qcbE1ok3rCtkterybUXE7ci8NjM5tux23TjHfIBMY4Licu/HM5cXc5adsMueowBe9rgpnDiVs62qYSu2+EaM2cTtw5mWr3jb5Tu/sQ6jlN3C5jQkud3vWJqarUD6Fm4hbQF2Ed9hwvs82Fux0XMTBxZ4hJ24+JC0nuwlU/OUEad+EiBpfhXhweh528CpcDc3AZLvwjXGei/EvjOtwoT2JEXMd1IOIL1PXENfP/pHr//rq4D9cs7pPrWYhw4U+YcD1OXY/fU6pQJ2fNJ1r9Qn3kaM0CTdx1yu+uqR53TqEmbhulKUyw78KH29QVRumgCfZ/YVcFaGPiJtjl/4zDdE1DuAOMiaordgLdDuFOjECnwY4LSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSXtVVVWlDwIYiokLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSX8BFGobMCOV5skAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "majority_voted = bncount_along_samples.argmax(-1)\n",
    "majority_voted.shape\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.axis('off')\n",
    "plt.imshow(majority_voted[:,:,64], interpolation='none', vmax=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdl_seg_class.metrics import dice3d\n",
    "test_dataset.eval()\n",
    "\n",
    "test_samples = []\n",
    "for sample in test_dataset:\n",
    "    test_samples.append(sample['label'])\n",
    "\n",
    "test_samples = torch.stack(test_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 128, 128, 128])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(test_samples.shape)\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.axis('off')\n",
    "plt.imshow(test_samples.sum(0)[:,:,64], interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6297)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice3d(\n",
    "    torch.nn.functional.one_hot(majority_voted).repeat(10,1,1,1,1),\n",
    "    torch.nn.functional.one_hot(test_samples),\n",
    "    one_hot_torch_style=True\n",
    ")[:,1:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_multilabel_staple_consensus(lbl_list):\n",
    "    staple_filter = sitk.MultiLabelSTAPLEImageFilter()\n",
    "    # sitk.ProcessObject.SetGlobalDefaultDebugOff()\n",
    "    staple_filter.SetMaximumNumberOfIterations(200)\n",
    "    staple_filter.SetLabelForUndecidedPixels(0)\n",
    "    sitk_moving_data = [sitk.GetImageFromArray(lbl.to_dense().numpy().astype(np.uint64)) for lbl in lbl_list]\n",
    "    \n",
    "    staple_out = staple_filter.Execute(sitk_moving_data)\n",
    "    consensus = torch.tensor(sitk.GetArrayFromImage(staple_out).astype(np.int64))\n",
    "\n",
    "    return consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "stapled = calc_multilabel_staple_consensus([smp for smp in train_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(stapled.unique())\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.axis('off')\n",
    "plt.imshow(stapled[:,:,64], interpolation='none', vmax=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testset vs. stapled: 54.372%\n",
      "testset vs. majority_voted: 62.972%\n"
     ]
    }
   ],
   "source": [
    "print(f\"testset vs. stapled: {dice3d(torch.nn.functional.one_hot(stapled).repeat(10,1,1,1,1),torch.nn.functional.one_hot(test_samples), one_hot_torch_style=True)[:,1:].mean().item()*100:.3f}%\")\n",
    "print(f\"testset vs. majority_voted: {dice3d(torch.nn.functional.one_hot(majority_voted).repeat(10,1,1,1,1),torch.nn.functional.one_hot(test_samples), one_hot_torch_style=True)[:,1:].mean().item()*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_slice_inflate import run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50e8264c9cb9bb8a6cada87af39a6b7aa8c2638398580ca823279198d429a8d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
