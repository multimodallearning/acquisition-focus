{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dir = Path(\"/shared/slice_inflate/data/output/20230314__11_19_08_dummy-o2sqp1hb\")\n",
    "\n",
    "hla_params_files = list(params_dir.glob('hla_params*.pt'))\n",
    "\n",
    "df = None\n",
    "\n",
    "for fl in hla_params_files:\n",
    "    mt = re.match(r\".*(train|test).*([0-9]{1,3})\\.pt\", str(fl))\n",
    "    phase, epoch = mt[1], int(mt[2])\n",
    "    param_dict = torch.load(fl)\n",
    "    epx_theta_aps = param_dict['epx_hla_theta_aps']\n",
    "    epx_theta_t_offsets = param_dict['epx_hla_theta_t_offsets']\n",
    "    epx_theta_zps = param_dict['epx_hla_theta_zps']\n",
    "\n",
    "    ids = list(zip(*sorted(epx_theta_aps.items())))[0]\n",
    "    theta_ap = list(zip(*sorted(epx_theta_aps.items())))[1]\n",
    "    theta_t_offsets = list(zip(*sorted(epx_theta_t_offsets.items())))[1]\n",
    "    theta_zp = list(zip(*sorted(epx_theta_zps.items())))[1]\n",
    "\n",
    "    data = dict(\n",
    "        view='hla', \n",
    "        sample=_id,\n",
    "        epoch=epoch,\n",
    "        theta_ap=theta_ap,\n",
    "        theta_t_offsets=theta_t_offsets,\n",
    "        theta_zp=theta_zp,\n",
    "        phase=phase,\n",
    "    )\n",
    "\n",
    "    if df is None:\n",
    "        df = pd.DataFrame(data)\n",
    "    else:\n",
    "        df = pd.concat([df, pd.DataFrame(data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>view</th>\n",
       "      <th>sample</th>\n",
       "      <th>epoch</th>\n",
       "      <th>theta_ap</th>\n",
       "      <th>theta_t_offsets</th>\n",
       "      <th>theta_zp</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hla</td>\n",
       "      <td>1001-mr</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.7136), tensor(0.5254), tensor(-0.027...</td>\n",
       "      <td>[tensor(0.0267), tensor(-0.0410), tensor(-0.02...</td>\n",
       "      <td>[tensor(1.)]</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  view   sample  epoch                                           theta_ap  \\\n",
       "0  hla  1001-mr      0  [tensor(0.7136), tensor(0.5254), tensor(-0.027...   \n",
       "\n",
       "                                     theta_t_offsets      theta_zp phase  \n",
       "0  [tensor(0.0267), tensor(-0.0410), tensor(-0.02...  [tensor(1.)]  test  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyvista'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnibabel\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnib\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyvista\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpv\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnibabel\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnib\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mCaution: pyvista plots require a machine with attached physical display or a display emulation (Xvfb package) - otherwise the kernel may die when generating renderings.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyvista'"
     ]
    }
   ],
   "source": [
    "import pymeshfix as mf\n",
    "import pyvista as pv\n",
    "\n",
    "assert False, \"Caution: pyvista plots require a machine with attached physical display or a display emulation (Xvfb package) - otherwise the kernel may die when generating renderings.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create mesh from shape voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import h5py\n",
    "import pymeshfix as mf\n",
    "import nibabel as nib\n",
    "import pyvista as pv\n",
    "from pathlib import Path\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_label_values(label):\n",
    "    # Replace label numbers with MMWHS equivalent\n",
    "    # STRUCTURE           MMWHS   ACDC    NNUNET\n",
    "    # background          0       0       0\n",
    "    # left_myocardium     205     2       1\n",
    "    # left_atrium         420     N/A     2\n",
    "    # ?                   421     N/A     N/A\n",
    "    # left_ventricle      500     3       3\n",
    "    # right_atrium        550     N/A     4\n",
    "    # right_ventricle     600     1       5\n",
    "    # ascending_aorta     820     N/A     6\n",
    "    # pulmonary_artery    850     N/A     7\n",
    "    orig_values = [0,  205, 420, 421, 500, 550, 600, 820, 850]\n",
    "    new_values = [0,  1,   2,   0,   3,   4,   5,   0,   0]\n",
    "\n",
    "    modified_label = label.clone()\n",
    "    for orig, new in zip(orig_values, new_values):\n",
    "        modified_label[modified_label == orig] = new\n",
    "    return modified_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CASE = \"1004\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_shape = nib.load(f\"mr_train_{CASE}_label_registered.nii.gz\")\n",
    "shape_data = replace_label_values(torch.as_tensor(nii_shape.get_fdata())).long()\n",
    "shape_affine = torch.as_tensor(nii_shape.affine)\n",
    "image_sample = nib.load(f\"mr_train_{CASE}_image_registered.nii.gz\").get_fdata()\n",
    "SPACING = (1.,1.,1.)\n",
    "STEP_SIZE = 2\n",
    "CLASSES = ['background', 'MYO', 'LA', 'LV', 'RA', 'RV']\n",
    "\n",
    "heart_data = {}\n",
    "for class_idx, tag in enumerate(CLASSES):\n",
    "    if class_idx == 0: continue\n",
    "\n",
    "    sub_label = torch.nn.functional.one_hot(shape_data.long(), len(CLASSES))[:,:,:, class_idx]\n",
    "    verts, faces, normals, values = measure.marching_cubes(sub_label.cpu().numpy(), spacing=SPACING, step_size=STEP_SIZE)\n",
    "    mm_verts = torch.cat([torch.tensor(verts.copy()), torch.ones(len(verts),1)], dim=1)\n",
    "    mm_verts = (shape_affine @ mm_verts.T.double()).T[:,:3]\n",
    "\n",
    "    data = dict(\n",
    "        verts=torch.as_tensor(mm_verts.numpy().copy()),\n",
    "        faces=torch.as_tensor(faces.copy()),\n",
    "        normals=torch.as_tensor(normals.copy()), \n",
    "        values=torch.as_tensor(values.copy())\n",
    "    )\n",
    "    heart_data[tag] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "optimized_sa_affines = []\n",
    "\n",
    "run_data_path = Path(\"/shared/slice_inflate/data/output/20230310__01_40_03_devout-brook-811-stage-1\")\n",
    "\n",
    "file_paths = list(run_data_path.glob('*.pt'))\n",
    "\n",
    "key = lambda _path: int(re.match(r\".*?([0-9]+)\\.pt\", str(_path))[1])\n",
    "file_paths.sort(key=key)\n",
    "\n",
    "for fl in file_paths:\n",
    "    content = torch.load(fl)\n",
    "    content.keys()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "mt = int(re.match(r\".*?([0-9]+)\\.pt\", str(file_paths))[1])\n",
    "print(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hla_mat = torch.from_numpy(np.loadtxt(\"mmwhs_1002_4CH.mat\"))\n",
    "sa_mat = torch.from_numpy(np.loadtxt(\"mmwhs_1002_SA.mat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_sa_mat_1004 = torch.tensor(\n",
    "    [[[ 0.3762,  0.0235, -0.9262,  0.0000],\n",
    "      [ 0.6500,  0.7056,  0.2820,  0.0000],\n",
    "      [ 0.6602, -0.7082,  0.2502,  0.0000],\n",
    "      [ 0.0000,  0.0000,  0.0000,  1.0000]]]\n",
    ")\n",
    "\n",
    "optimized_hla_mat_1004 = torch.tensor(\n",
    "    [[[ 0.8096, -0.5865,  0.0236,  0.0000],\n",
    "      [ 0.5751,  0.7844, -0.2325,  0.0000],\n",
    "      [ 0.1178,  0.2018,  0.9723,  0.0000],\n",
    "      [ 0.0000,  0.0000,  0.0000,  1.0000]]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from align_mmwhs import nifti_transform\n",
    "FOV_MM = torch.tensor([224,224,224])\n",
    "FOV_VOX = torch.tensor([160,160,160])\n",
    "\n",
    "with torch.no_grad():\n",
    "    sa_label, sa_affine, sa_grid_affine = nifti_transform(shape_data.unsqueeze(0).unsqueeze(0), shape_affine.unsqueeze(0), sa_mat.unsqueeze(0), \n",
    "        fov_mm=FOV_MM, fov_vox=FOV_VOX, is_label=True, \n",
    "        # pre_grid_sample_affine=optimized_sa_mat_1004,\n",
    "        pre_grid_sample_affine=None\n",
    "    )\n",
    "    \n",
    "    hla_label, hla_affine, hla_grid_affine = nifti_transform(shape_data.unsqueeze(0).unsqueeze(0), shape_affine.unsqueeze(0), hla_mat.unsqueeze(0), \n",
    "        fov_mm=FOV_MM, fov_vox=FOV_VOX, is_label=True, \n",
    "        # pre_grid_sample_affine=optimized_hla_mat_1004,\n",
    "        pre_grid_sample_affine=None\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(sa_label.squeeze()[:,:,80].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(hla_label.squeeze()[:,:,80].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nifti original plane slicing.\n",
    "# sa_normal = torch.tensor([1.,0.,0.])  # working! for D slicing\n",
    "# sa_normal = torch.tensor([0.,1.,0.])  # working! for H slicing\n",
    "\n",
    "sa_normal = torch.tensor([0.,0.,1.])  # working! for W slicing\n",
    "sa_support = (shape_affine @ torch.tensor([64.,64.,64.,1.]).double())[:3]\n",
    "print(\"Non transformed\", sa_normal, sa_support)\n",
    "\n",
    "# SA slicing\n",
    "sa_normal = (sa_affine @ torch.tensor([0.,0.,1.,0.]).double())[0,:3]\n",
    "sa_support = (sa_affine @ torch.tensor([80.,80.,80.,1.]).double())[0,:3]\n",
    "\n",
    "print(\"Transformed SA\", sa_normal, sa_support)\n",
    "\n",
    "hla_normal = (hla_affine @ torch.tensor([0.,0.,1.,0.]).double())[0,:3]\n",
    "hla_support =(hla_affine @ torch.tensor([80.,80.,80.,1.]).double())[0,:3]\n",
    "print(\"Transformed HLA\", hla_normal, hla_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_vertices = heart_data['MYO']['verts']\n",
    "h_faces = heart_data['MYO']['faces']\n",
    "\n",
    "for tag, data in heart_data.items():\n",
    "    faces = data['faces']\n",
    "    num_faces = faces.shape[0]\n",
    "    num_points = torch.tensor([3]*num_faces).view(num_faces,1)\n",
    "    data['pyvista_faces'] = torch.cat([num_points, faces], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://coolors.co/b8336a-726da8-7d8cc4-a0d2db-c490d1\n",
    "\n",
    "palette = [\n",
    "    '#B8336A',\n",
    "    '#726DA8',\n",
    "    '#7D8CC4',\n",
    "    '#A0D2DB',\n",
    "    '#C490D1',\n",
    "]\n",
    "dark_palette = [\n",
    "    '#4F172E', \n",
    "    '#424064',\n",
    "    '#485070',\n",
    "    '#547378',\n",
    "    '#73507C',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_FULL_MESH = False\n",
    "\n",
    "SHOW_SA_PLANE = True\n",
    "SHOW_SA_SLICE = True\n",
    "\n",
    "SHOW_HLA_PLANE = True\n",
    "SHOW_HLA_SLICE = True\n",
    "\n",
    "CPOS = [\n",
    "    (456.42537425592207, -476.3133591268548, 11.507223342275584),\n",
    "    (-49.71246948463747, 0.5437890350509349, -5.752938139380589),\n",
    "    (0.6710467014241088, 0.7038135452178427, -0.23311546082513432)\n",
    "]\n",
    "\n",
    "plotter = pv.Plotter(\n",
    "    lighting='three lights'\n",
    ")\n",
    "plotter.background_color = \"white\"\n",
    "\n",
    "cpos = 'iso'\n",
    "sa_plane = pv.Plane(center=sa_support.tolist(), direction=sa_normal.tolist(), i_size=200, j_size=200, i_resolution=1, j_resolution=1)\n",
    "sa_plane.point_data.clear()\n",
    "sa_edges = sa_plane.extract_feature_edges(boundary_edges=True, feature_edges=False, manifold_edges=False)\n",
    "\n",
    "hla_plane = pv.Plane(center=hla_support.tolist(), direction=hla_normal.tolist(), i_size=200, j_size=200, i_resolution=1, j_resolution=1)\n",
    "hla_plane.point_data.clear()\n",
    "hla_edges = hla_plane.extract_feature_edges(boundary_edges=True, feature_edges=False, manifold_edges=False)\n",
    "\n",
    "full_mesh = []\n",
    "\n",
    "# Prepare meshes\n",
    "for idx, (tag, data) in enumerate(heart_data.items()):\n",
    "    surf = pv.PolyData(data['verts'].numpy(), data['pyvista_faces'].view(-1).numpy())\n",
    "    scalars=np.array([idx]*data['verts'].shape[0])\n",
    "    surf.point_data.set_scalars(scalars, 'scalars')\n",
    "    # full_mesh.append(surf)\n",
    "    smooth = surf.smooth_taubin(n_iter=100, pass_band=0.3)\n",
    "    full_mesh.append(smooth)\n",
    "\n",
    "block = pv.MultiBlock(full_mesh)\n",
    "full_mesh = block.combine(merge_points=False)\n",
    "\n",
    "sa_slice = full_mesh.slice(normal=sa_normal.tolist(), origin=sa_support.tolist())\n",
    "hla_slice = full_mesh.slice(normal=hla_normal.tolist(), origin=hla_support.tolist())\n",
    "\n",
    "if SHOW_FULL_MESH:\n",
    "    plotter.add_mesh(full_mesh, name='all', cmap=palette, line_width=2, show_scalar_bar=False, smooth_shading=True)   \n",
    "\n",
    "if SHOW_SA_SLICE:\n",
    "    plotter.add_mesh(sa_slice, name=tag +'_sa_slice', cmap=palette, line_width=2, show_scalar_bar=False) \n",
    "\n",
    "if SHOW_SA_PLANE:   \n",
    "    plotter.add_mesh(sa_plane, color=palette[idx],  opacity=0.3, show_edges=False, line_width=2)\n",
    "    plotter.add_mesh(sa_edges, color=dark_palette[idx], line_width=1)\n",
    "\n",
    "if SHOW_HLA_SLICE:\n",
    "    plotter.add_mesh(hla_slice, name=tag +'_hla_slice', cmap=palette, line_width=2, show_scalar_bar=False)\n",
    "\n",
    "if SHOW_HLA_PLANE:    \n",
    "    plotter.add_mesh(hla_plane, color=palette[idx],  opacity=0.3, show_edges=False, line_width=2)\n",
    "    plotter.add_mesh(hla_edges, color=dark_palette[idx], line_width=1)\n",
    "\n",
    "plotter.view_isometric()\n",
    "plotter.enable_parallel_projection()\n",
    "\n",
    "# plotter.camera.position = (hla_support+hla_normal).tolist()\n",
    "# plotter.camera.focal_point = hla_support.tolist()\n",
    "# plotter.camera.up = (0.0, 1.0, 0.0)\n",
    "plotter.camera.zoom(1.2)\n",
    "\n",
    "plotter.show(\n",
    "    window_size=[1200,1200], \n",
    "    # jupyter_backend='static',\n",
    "    cpos=CPOS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.camera_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da46a6541ad1ebd554a6d91c7d93891a249a9a187bd5c787406972a8a9c6b0a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
